Most of the readers of this book are likely to be around to experience the Singularity. As we reviewed in the previous
chapter, accelerating progress in biotechnology will enable us to reprogram our genes and metabolic processes to turn
off disease and aging processes. This progress will include rapid advances in genomics (influencing genes),
proteomics (understanding and influencing the role of proteins), gene therapy (suppressing gene expression with such
technologies as RNA interference and inserting new genes into the nucleus), rational drug design (formulating drugs
that target precise changes in disease and aging processes), and therapeutic cloning of rejuvenated (telomere-extended
and DNA-corrected) versions of our own cells, tissues, and organs, and related developments.
Biotechnology will extend biology and correct its obvious flaws. The overlapping revolution of nanotechnology
will enable us to expand beyond the severe limitations of biology. As Terry Grossman and I articulated in Fantastic
Voyage: Live Long Enough to Live Forever, we are rapidly gaining the knowledge and the tools to indefinitely
maintain and extend the "house" each of us calls his body and brain. Unfortunately the vast majority of our baby-
boomer peers are unaware of the fact that they do not have to suffer and die in the "normal" course of life, as prior
generations have done—if they take aggressive action, action that goes beyond the usual notion of a basically healthy
lifestyle (see "Resources and Contact Information," p. 489).
Historically, the only means for humans to outlive a limited biological life span has been to pass on values,
beliefs, and knowledge to future generations. We are now approaching a paradigm shift in the means we will have
available to preserve the patterns underlying our existence. Human life expectancy is itself growing steadily and will
accelerate rapidly, now that we are in the early stages of reverse engineering the information processes underlying life
and disease. Robert Freitas estimates that eliminating a specific list comprising 50 percent of medically preventable
conditions would extend human life expectancy to over 150 years.39 By preventing 90 percent of medical problems,
life expectancy grows to over five hundred years. At 99 percent, we'd be over one thousand years. We can expect that
the full realization of the biotechnology and nanotechnology revolutions will enable us to eliminate virtually all
medical causes of death. As we move toward a nonbiological existence, we will gain the means of "backing ourselves
up" (storing the key patterns underlying our knowledge, skills, and personality), thereby eliminating most causes of
death as we know it.
The Transformation to Nonbiological Experience
A mind that stays at the same capacity cannot live forever; after a few thousand years it would look more like
a repeating tape loop than a person. To live indefinitely long, the mind itself must grow, ... and when it
becomes great enough, and looks back ... what fellow feeling can it have with the soul that it was originally?
The later being would be everything the original was, but vastly more.
—VERNOR VINGE
The empires of the future are the empires of the mind.
—WINSTON CHURCHILL
I reported on brain uploading in chapter 4. The straightforward brain-porting scenario involves scanning a human brain
(most likely from within), capturing all of the salient details, and reinstantiating the brain's state in a different—most
likely much more powerful—computational substrate. This will be a feasible procedure and will happen most likely
around the late 2030s. But this is not the primary way that I envision the transition to nonbiological experience taking
place. It will happen, rather, in the same way that all other paradigm shifts happen: gradually (but at an accelerating
pace).
As I pointed out above, the shift to nonbiological thinking will be a slippery slope, but one on which we have
already started. We will continue to have human bodies, but they will become morphable projections of our
intelligence. In other words, once we have incorporated MNT fabrication into ourselves, we will be able to create and
re-create different bodies at will.
However achieved, will such fundamental shifts enable us to live forever? The answer depends on what we mean
by "living" and "dying." Consider what we do today with our personal computer files. When we change from an older
computer to a newer one, we don't throw all our files away. Rather, we copy them and reinstall them on the new
hardware. Although our software does not necessarily continue its existence forever, its longevity is in essence
independent of and disconnected from the hardware that it runs on.
Currently, when our human hardware crashes, the software of our lives—our personal "mind file"—dies with it.
However, this will not continue to be the case when we have the means to store and restore the thousands of trillions of
bytes of information represented in the pattern that we call our brains (together with the rest of our nervous system,
endocrine system, and other structures that our mind file comprises).
At that point the longevity of one's mind file will not depend on the continued viability of any particular hardware
medium (for example, the survival of a biological body and brain). Ultimately software-based humans will be vastly
extended beyond the severe limitations of humans as we know them today. They will live out on the Web, projecting
bodies whenever they need or want them, including virtual bodies in diverse realms of virtual reality, holographically
projected bodies, foglet-projected bodies, and physical bodies comprising nanobot swarms and other forms of
nanotechnology.
By the middle of the twenty-first century humans will be able to expand their thinking without limit. This is a
form of immortality, although it is important to point out that data and information do not necessarily last forever: the
longevity of information depends on its relevance, utility, and accessibility. If you've ever tried to retrieve information
from an obsolete form of data storage in an old, obscure format (for example, a reel of magnetic tape from a 1970
minicomputer), you understand the challenges in keeping software viable. However, if we are diligent in maintaining
our mind file, making frequent backups, and porting to current formats and mediums, a form of immortality can be
attained, at least for software-based humans. Later in this century it will seem remarkable to people that humans in an
earlier era lived their lives without a backup of their most precious information: that contained in their brains and
bodies.
Is this form of immortality the same concept as a physical human, as we know it today, living forever? In one
sense it is, because today one's self is not a constant collection of matter, either. Recent research shows that even our
neurons, thought to be relatively long lasting, change all of their constituent subsystems, such as the tubules, in a
matter of weeks. Only our pattern of matter and energy persists, and even that gradually changes. Similarly, it will be
the pattern of a software human that persists and develops and slowly alters.
But is that person based on my mind file, who migrates across many computational substrates and who outlives
any particular thinking medium, really me? This consideration takes us back to the same questions of consciousness
and identity that have been debated since Plato's dialogues (which we examine in the next chapter). During the course
of the twenty-first century these will not remain topics for polite philosophical debates but will have to be confronted
as vital, practical, political, and legal issues.
A related question: Is death desirable? The "inevitability" of death is deeply ingrained in human thinking. If death
seems unavoidable, we have little choice but to rationalize it as necessary, even ennobling. The technology of the
Singularity will provide practical and accessible means for humans to evolve into something greater, so we will no
longer need to rationalize death as a primary means of giving meaning to life.
The Longevity of Information
"The horror of that moment," the King went on, "I shall never, never forget it!" "You will, though," the
Queen said, "if you don't make a memorandum of it."
—LEWIS CARROLL, THROUGH THE LOOKING-GLASS
The only things you can be sure of, so the saying goes, are death and taxes—but don't be too sure about death.
—JOSEPH STROUT, NEUROSCIENTIST
I do not know sire, but whatever they will turn out to be I am sure you will tax them.
—MICHAEL FARADAY, RESPONDING TO A QUESTION FROM THE BRITISH EXCHEQUER AS TO
WHAT PRACTICAL USE COULD BE MADE OF HIS DEMONSTRATION OF ELECTROMAGNETISM
Do not go gentle into that good night, ...
Rage, rage against the dying of the light.
—DYLAN THOMAS
The opportunity to translate our lives, our history, our thoughts, and our skills into information raises the issue of how
long information lasts. I've always revered knowledge and gathered information of all kinds as a child, an inclination I
shared with my father.
By way of background, my father was one of those people who liked to store all the images and sounds that
documented his life. Upon his untimely death at the age of fifty-eight in 1970, I inherited his archives, which I treasure
to this day. I have my father's 1938 doctoral dissertation from the University of Vienna, which contains his unique
insights into the contributions of Brahms to our musical vocabulary. There are albums of neatly arranged newspaper
clippings of his acclaimed musical concerts as a teenager in the hills of Austria. There are urgent letters to and from
the American music patron who sponsored his flight from Hitler, just before Kristallnacht and related historical
developments in Europe in the late 1930s made such escape impossible. These items are among dozens of aging boxes
containing a myriad of remembrances, including photographs, musical recordings on vinyl and magnetic tape, personal
letters, and even old bills.
I also inherited his penchant for preserving the records of one's life, so along with my father's boxes I have several
hundred boxes of my own papers and files. My father's productivity, assisted only by the technology of his manual
typewriter and carbon paper, cannot compare with my own prolificacy, aided and abetted by computers and high-
speed printers that can reproduce my thoughts in all kinds of permutations.
Tucked away in my own boxes are also various forms of digital media: punch cards, paper-tape reels, and digital
magnetic tapes and disks of various sizes and formats. I often wonder just how accessible this information remains.
Ironically the ease of approaching this information is inversely proportional to the level of advancement of the
technology used to create it. Most straightforward are the paper documents, which although showing signs of age are
eminently readable. Only slightly more challenging are the vinyl records and analog tape recordings. Although some
basic equipment is required, it is not difficult to find or use. The punch cards are somewhat more challenging, but it's
still possible to find punch-card readers, and the formats are uncomplicated.
By far the most demanding information to retrieve is that contained on the digital disks and tapes. Consider the
challenges involved. For each medium I have to figure out exactly which disk or tape drive was used, whether an IBM
1620 circa 1960 or a Data General Nova I circa 1973.Then, once I've assembled the requisite equipment, there are
layers of software to deal with: the appropriate operating system, disk information drivers, and application programs.
And, when I run into the inevitable scores of problems inherent in each layer of hardware and software, just whom am
I going to call for assistance? It's hard enough getting contemporary systems to work, let alone systems for which the
help desks were disbanded decades ago (if they ever existed). Even at the Computer History Museum most of the
devices on display stopped functioning many years ago.41
Assuming I do prevail against all of these obstacles, I have to account for the fact that the actual magnetic data on
the disks has probably decayed and that the old computers would still generate mostly error messages.42 But is the
information gone? The answer is, Not entirely. Even though the magnetic spots may no longer be readable by the
original equipment, the faded regions could be enhanced by suitably sensitive equipment, via methods that are
analogous to the image enhancement often applied to the pages of old books when they are scanned. The information
is still there, although very difficult to get at. With enough devotion and historical research, one might actually retrieve
it. If we had reason to believe that one of these disks contained secrets of enormous value, we would probably succeed
in recovering the information.
But mere nostalgia is unlikely to be sufficient to motivate anyone to undertake this formidable task. I will say that
because I did largely anticipate this dilemma, I did make paper printouts of most of these old files. But keeping all our
information on paper is not the answer, as hard-copy archives present their own set of problems. Although I can
readily read even a century-old paper manuscript if I'm holding it in my hand, finding a desired document from among
thousands of only modestly organized file folders can be a frustrating and time-consuming task. It can take an entire
afternoon to locate the right folder, not to mention the risk of straining one's back from moving dozens of heavy file
boxes. Using microfilm or microfiche may alleviate some of the difficulty, but the matter of locating the right
document remains.
I have dreamed of taking these hundreds of thousands of records and scanning them into a massive personal
database, which would allow me to utilize powerful contemporary search-and-retrieve methods on them. I even have a
name for this venture—DAISI (Document and Image Storage Invention)—and have been accumulating ideas for it for
many years. Computer pioneer Gordon Bell (former chief engineer of Digital Equipment Corporation), DARPA
(Defense Advanced Research Projects Agency), and the Long Now Foundation are also working on systems to address
this challenge.43
DAISI will involve the rather daunting task of scanning and patiently cataloging all these documents. But the real
challenge to my dream of DAISI is surprisingly deep: how can I possibly select appropriate hardware and software
layers that will give me the assurance that my archives will be viable and accessible decades from now?
Of course my own archival needs are only a microcosm of the exponentially expanding knowledge base that
human civilization is accumulating. It is this shared species-wide knowledge base that distinguishes us from other
animals. Other animals communicate, but they don't accumulate an evolving and growing base of knowledge to pass
down to the next generation. Since we are writing our precious heritage in what medical informatics expert Bryan
Bergeron calls "disappearing ink," our civilization's legacy would appear to be at great risk.44 The danger appears to be
growing exponentially along with the growth of our knowledge bases. The problem is further exacerbated by the
accelerating speed with which we adopt new standards in the many layers of hardware and software we employ to
store information.
There is another valuable repository of information stored in our brains. Our memories and skills, although they
may appear to be fleeting, do represent information, coded in vast patterns of neurotransmitter concentrations,
interneuronal connections, and other relevant neural details. This information is the most precious of all, which is one
reason death is so tragic. As we have discussed, we will ultimately be able to access, permanently archive, as well as
understand the thousands of trillions of bytes of information we have tucked away in each of our brains.
Copying our minds to other mediums raises a number of philosophical issues, which I will discuss in the next
chapter—for example, "Is that really me or rather someone else who just happens to have mastered all my thoughts
and knowledge?" Regardless of how we resolve these issues, the idea of capturing the information and information
processes in our brains seems to imply that we (or at least entities that act very much like we do) could "live forever."
But is that really the implication?
For eons the longevity of our mental software has been inexorably linked to the survival of our biological
hardware. Being able to capture and reinstantiate all the details of our information processes would indeed separate
these two aspects of our mortality. But as we have seen, software itself does not necessarily survive forever, and there
are formidable obstacles to its enduring very long at all.
So whether information represents one man's sentimental archive, the accumulating knowledge base of the
human-machine civilization, or the mind files stored in our brains, what can we conclude about the ultimate longevity
of software? The answer is simply this: Information lasts only so long as someone cares about it. The conclusion that
I've come to with regard to my DAISI project, after several decades of careful consideration, is that there is no set of
hardware and software standards existing today, nor any likely to come along, that will provide any reasonable level of
confidence that the stored information will still be accessible (without unreasonable levels of effort) decades from
now.45 The only way that my archive (or any other information base) can remain viable is if it is continually upgraded
and ported to the latest hardware and software standards. If an archive remains ignored, it will ultimately become as
inaccessible as my old eight-inch PDP-8 floppy disks.
Information will continue to require constant maintenance and support to remain "alive." Whether data or wisdom,
information will survive only if we want it to. By extension, we can only live for as long as we care about ourselves.
Already our knowledge to control disease and aging is advanced to the point that your attitude toward your own
longevity is now the most important influence on your long-range health.
Our civilization's trove of knowledge does not simply survive by itself. We must continually rediscover,
reinterpret, and reformat the legacy of culture and technology that our forebears have bestowed on us. All of this
information will be fleeting if no one cares about it. Translating our currently hardwired thoughts into software will
not necessarily provide us with immortality. It will simply place the means to determine how long we want our lives
and thoughts to last in our own figurative hands.
MOLLY 2004: So what you're saying is that I'm just a file?
MOLLY 2104: Well, not a static file, but a dynamic file. But what do you mean "just"? What could be more
important?
MOLLY 2004: Well, I throw files away all the time, even dynamic ones.
MOLLY 2104: Not all files are created equal.
MOLLY 2004: I suppose that's true. I was devastated when I lost my only copy of my senior thesis. I lost six months of
work and had to start over.
MOLLY 2104: Ah, yes, that was awful. I remember it well, even though it was over a century ago. It was devastating
because it was a small part of myself. I had invested my thoughts and creativity in that file of information. So
think how precious all of your—my—accumulated thoughts, experience, skills, and history are.
. . . on Warfare: The Remote, Robotic, Robust, Size-Reduced, Virtual-Reality Paradigm
As weapons have become more intelligent, there has been a dramatic trend toward more precise missions with fewer
casualties. It may not seem that way when viewed alongside the tendency toward more detailed, realistic television-
news coverage. The great battles of World Wars I and II and the Korean War, in which tens of thousands of lives were
lost over the course of a few days, were visually recorded only by occasional grainy newsreels. Today, we have a
front-row seat for almost every engagement. Each war has its complexities, but the overall movement toward precision
intelligent warfare is clear by examining the number of casualties. This trend is similar to what we are beginning to see
in medicine, where smart weapons against disease are able to perform specific missions with far fewer side effects.
The trend is similar for collateral casualties, although it may not seem that way from contemporary media coverage
(recall that about fifty million civilians died in World War II).
I am one of five members of the Army Science Advisory Group (ASAG), which advises the U.S. Army on
priorities for its science research. Although our briefings, deliberations, and recommendations are confidential, I can
share some overall technological directions that are being pursued by the army and all of the U.S. armed forces.
Dr. John A. Parmentola, director for research and laboratory management for the U.S. Army and liaison to the
ASAG, describes the Department of Defense's "transformation" process as a move toward an armed force that is
"highly responsive, network-centric, capable of swift decision, superior in all echelons, and [able to provide]
overwhelming massed effects across any battle space."46 He describes the Future Combat System (FCS), now under
development and scheduled to roll out during the second decade of this century, as "smaller, lighter, faster, more
lethal, and smarter."
Dramatic changes are planned for future war-fighting deployments and technology. Although details are likely to
change, the army envisions deploying Brigade Combat Teams (BCTs) of about 2,500 soldiers, unmanned robotic
systems, and FCS equipment. A single BCT would represent about 3,300 "platforms," each with its own intelligent
computational capabilities. The BCT would have a common operating picture (COP) of the battlefield, which would
be appropriately translated for it, with each soldier receiving information through a variety of means, including retinal
(and other forms of "heads up") displays and, in the future, direct neural connection.
The army's goal is to be capable of deploying a BCT in 96 hours and a full division in 120 hours. The load for
each soldier, which is now about one hundred pounds of equipment, will initially be reduced through new materials
and devices to forty pounds, while dramatically improving effectiveness. Some of the equipment would be offloaded
to "robotic mules."
A new uniform material has been developed using a novel form of Kevlar with silica nanoparticles suspended in
polyethylene glycol. The material is flexible in normal use, but when stressed it instantly forms a nearly impenetrable
mass that is stab resistant. The army's Institute for Soldier Nanotechnologies at MIT is developing a nanotechnology-
based material called "exomuscle" to enable combatants to greatly increase their physical strength when manipulating
heavy equipment.47
The Abrams tank has a remarkable survival record, with only three combat casualties in its twenty years of
combat use. This is the result of both advanced armor materials and of intelligent systems designed to defeat incoming
weapons, such as missiles. However, the tank weighs more than seventy tons, a figure that will need to be significantly
reduced to meet FCS goals for smaller systems.
New lightweight yet ultrastrong nanomaterials (such as plastics combined with nanotubes, which are fifty times
stronger than steel), as well as increased computer intelligence to counteract missile attacks, are expected to
dramatically lower the weight of ground combat systems.
The trend toward unmanned aerial vehicles (DAVs), which started with the armed Predator in the recent
Afghanistan and Iraq campaigns, will accelerate. Army research includes the development of micro-DAYs the size of
birds that will be fast, accurate, and capable of performing both reconnaissance and combat missions. Even smaller
DAVs the size of bumblebees are envisioned. The navigational ability of an actual bumblebee, which is based on a
complex interaction between its left and right vision systems, has recently been reverse engineered and will be applied
to these tiny flying machines.
At the center of the FCS is a self-organizing, highly distributed communications network capable of gathering
information from each soldier and each piece of equipment and in turn providing the appropriate information displays
and files back to each human and machine participant. There will be no centralized communications hubs that could be
vulnerable to hostile attack. Information will rapidly route itself around damaged portions of the network. An obvious
top priority is to develop technology capable of maintaining integrity of communication and preventing either
eavesdropping or manipulation of information by hostile forces. The same information-security technology will be
applied to infiltrate, disrupt, confuse, or destroy enemy communications through both electronic means and
cyberwarfare using software pathogens.
The FCS is not a one-shot program; it represents a pervasive focus of military systems toward remotely guided,
autonomous, miniaturized, and robotic systems, combined with robust, self-organizing, distributed, and secure
communications.
The U.S. Joint Forces Command's Project Alpha (responsible for accelerating transformative ideas throughout the
armed services) envisions a 2025 fighting force that "is largely robotic," incorporating tactical autonomous combatants
(TACs) that "have some level of autonomy-adjustable autonomy or supervised autonomy or full autonomy within . . .
mission bounds."48 The TACs will be available in a wide range of sizes, ranging from nanobots and microbots up to
large UAVs and other vehicles, as well as automated systems that can walk through complex terrains. One innovative
design being developed by NASA with military applications envisioned is in the form of a snake.49
One of the programs contributing to the 2020s concept of self-organizing swarms of small robots is the
Autonomous Intelligent Network and Systems (AINS) program of the Office of Naval Research, which envisions a
drone army of unmanned, autonomous robots in the water, on the ground, and in the air. The swarms will have human
commanders with decentralized command and control and what project head Allen Moshfegh calls an "impregnable
Internet in the sky."50
Extensive research is going into designing swarm intelligence.51 Swarm intelligence describes the way that
complex behaviors can arise from large numbers of individual agents, each following relatively simple rules.52 Swarms
of insects are often able to devise intelligent solutions to complex problems, such as designing the architecture of a
colony, despite the fact that no single member of the swarm possesses the requisite skills.
DARPA announced in 2003 that a battalion of 120 military robots (built by I-Robot, a company cofounded by
robotics pioneer Rodney Brooks) was to be fitted with swarm-intelligence software to enable it to mimic the organized
behavior of insects.53 As robotic systems become physically smaller and larger in number, the principles of self-
organizing swarm intelligence will play an increasingly important role.
There is also recognition in the military that development times need to be reduced. Historically, the typical time
period for military projects to go from research to deployment has been longer than a decade. But with the technology
paradigm-shift rate coming down by half every decade, these development times need to keep pace, as many weapons
systems are already obsolete by the time they reach the field. One way to accomplish this is to develop and test new
weapons using simulations, which enable weapons systems to be designed, implemented, and tested far more quickly
than the traditional means of building prototypes and testing them (often by blowing them up) in actual use.
Another key trend is to move personnel away from combat to improve soldiers' rates of survival. This can be done
by allowing humans to drive and pilot systems remotely. Taking the pilot out of a vehicle allows it to take part in
riskier missions and to be designed to be far more maneuverable. It also allows the devices to become very small by
dispensing with the extensive requirements for supporting human life. The generals are moving even farther away.
Tommy Franks conducted the war in Afghanistan from his bunker in Qatar.
Smart Dust. DARPA is developing devices even tinier than birds and bumblebees called "smart dust"—complex
sensor systems not much bigger than a pinhead. Once fully developed, swarms of millions of these devices could be
dropped into enemy territory to provide highly detailed surveillance and ultimately support offensive warfare missions
(for example, releasing nanoweapons). Power for smart-dust systems will be provided by nanoengineered fuel cells, as
well as by conversion of mechanical energy from their own movement, wind, and thermal currents.
Want to find a key enemy? Need to locate hidden weapons? Massive numbers of essentially invisible spies could
monitor every square inch of enemy territory, identify every person (through thermal and electromagnetic imaging,
eventually DNA tests, and other means) and every weapon and even carry out missions to destroy enemy targets.
Nanoweapons. The next step beyond smart dust will be nanotechnology-based weapons, which will make obsolete
weapons of larger size. The only way for an enemy to counteract such a massively distributed force will be with its
own nanotechnology. In addition, enhancing nanodevices with the ability to self-replicate will extend their capabilities
but introduces grave dangers, a subject I address in chapter 8.
Nanotechnology is already being applied to a wide range of military functions. These include nanotech coatings
for improved armor; laboratories on a chip for rapid chemical and biological-agent detection and identification;
nanoscale catalysts for decontaminating areas; smart materials that can restructure themselves for different situations;
biocidal nanoparticles incorporated into uniforms to reduce infection from injuries; nanotubes combined with plastics
to create extremely strong materials; and self-healing materials. For example, the University of Illinois has developed
self-healing plastics that incorporate microspheres of liquid monomers and a catalyst into a plastic matrix; when a
crack appears, the microspheres break, automatically sealing the crack.54
Smart Weapons. We've already moved from dumb missiles launched with hopes they will find their targets to
intelligent cruise missiles that use pattern recognition to make thousands of tactical decisions on their own. Bullets,
however, have remained essentially small dumb missiles, and providing them with a measure of intelligence is another
military objective.
As military weapons become smaller in size and larger in number, it won't be desirable or feasible to maintain
human control over each device. So increasing the level of autonomous control is another important goal. Once
mach
====================================================================
The Coming Technological Singularity:
How to Survive in the Post-Human Era
Vernor Vinge
Department of Mathematical Sciences
San Diego State University
(c) 1993 by Vernor Vinge
(Verbatim copying/translation and distribution of this
entire article is permitted in any medium, provided this
notice is preserved.)
This article was for the VISION-21 Symposium
sponsored by NASA Lewis Research Center
and the Ohio Aerospace Institute, March 30-31, 1993.
It is also retrievable from the NASA technical reports
server as part of NASA CP-10129.
A slightly changed version appeared in the
Winter 1993 issue of _Whole Earth Review_.
Abstract
Within thirty years, we will have the technological
means to create superhuman intelligence. Shortly after,
the human era will be ended.
Is such progress avoidable? If not to be avoided, can
events be guided so that we may survive? These questions
are investigated. Some possible answers (and some further
dangers) are presented.
_What is The Singularity?_
The acceleration of technological progress has been the central
feature of this century. I argue in this paper that we are on the edge
of change comparable to the rise of human life on Earth. The precise
cause of this change is the imminent creation by technology of
entities with greater than human intelligence. There are several means
by which science may achieve this breakthrough (and this is another
reason for having confidence that the event will occur):
o The development of computers that are "awake" and
superhumanly intelligent. (To date, most controversy in the
area of AI relates to whether we can create human equivalence
in a machine. But if the answer is "yes, we can", then there
is little doubt that beings more intelligent can be constructed
shortly thereafter.
o Large computer networks (and their associated users) may "wake
up" as a superhumanly intelligent entity.
o Computer/human interfaces may become so intimate that users
may reasonably be considered superhumanly intelligent.
o Biological science may find ways to improve upon the natural
human intellect.
The first three possibilities depend in large part on
improvements in computer hardware. Progress in computer hardware has
followed an amazingly steady curve in the last few decades [16]. Based
largely on this trend, I believe that the creation of greater than
human intelligence will occur during the next thirty years. (Charles
Platt [19] has pointed out the AI enthusiasts have been making claims
like this for the last thirty years. Just so I'm not guilty of a
relative-time ambiguity, let me more specific: I'll be surprised if
this event occurs before 2005 or after 2030.)
What are the consequences of this event? When greater-than-human
intelligence drives progress, that progress will be much more rapid.
In fact, there seems no reason why progress itself would not involve
the creation of still more intelligent entities -- on a still-shorter
time scale. The best analogy that I see is with the evolutionary past:
Animals can adapt to problems and make inventions, but often no faster
than natural selection can do its work -- the world acts as its own
simulator in the case of natural selection. We humans have the ability
to internalize the world and conduct "what if's" in our heads; we can
solve many problems thousands of times faster than natural selection.
Now, by creating the means to execute those simulations at much higher
speeds, we are entering a regime as radically different from our human
past as we humans are from the lower animals.
From the human point of view this change will be a throwing away
of all the previous rules, perhaps in the blink of an eye, an
exponential runaway beyond any hope of control. Developments that
before were thought might only happen in "a million years" (if ever)
will likely happen in the next century. (In [4], Greg Bear paints a
picture of the major changes happening in a matter of hours.)
I think it's fair to call this event a singularity ("the
Singularity" for the purposes of this paper). It is a point where our
models must be discarded and a new reality rules. As we move closer
and closer to this point, it will loom vaster and vaster over human
affairs till the notion becomes a commonplace. Yet when it finally
happens it may still be a great surprise and a greater unknown. In
the 1950s there were very few who saw it: Stan Ulam [27] paraphrased
John von Neumann as saying:
One conversation centered on the ever accelerating progress of
technology and changes in the mode of human life, which gives the
appearance of approaching some essential singularity in the
history of the race beyond which human affairs, as we know them,
could not continue.
Von Neumann even uses the term singularity, though it appears he
is still thinking of normal progress, not the creation of superhuman
intellect. (For me, the superhumanity is the essence of the
Singularity. Without that we would get a glut of technical riches,
never properly absorbed (see [24]).)
In the 1960s there was recognition of some of the implications of
superhuman intelligence. I. J. Good wrote [10]:
Let an ultraintelligent machine be defined as a machine
that can far surpass all the intellectual activities of any
any man however clever. Since the design of machines is one of
these intellectual activities, an ultraintelligent machine could
design even better machines; there would then unquestionably
be an "intelligence explosion," and the intelligence of man
would be left far behind. Thus the first ultraintelligent
machine is the _last_ invention that man need ever make,
provided that the machine is docile enough to tell us how to
keep it under control.
...
It is more probable than not that, within the twentieth century,
an ultraintelligent machine will be built and that it will be
the last invention that man need make.
Good has captured the essence of the runaway, but does not pursue
its most disturbing consequences. Any intelligent machine of the sort
he describes would not be humankind's "tool" -- any more than humans
are the tools of rabbits or robins or chimpanzees.
Through the '60s and '70s and '80s, recognition of the cataclysm
spread [28] [1] [30] [4]. Perhaps it was the science-fiction writers
who felt the first concrete impact. After all, the "hard"
science-fiction writers are the ones who try to write specific stories
about all that technology may do for us. More and more, these writers
felt an opaque wall across the future. Once, they could put such
fantasies millions of years in the future [23]. Now they saw that
their most diligent extrapolations resulted in the unknowable ...
soon. Once, galactic empires might have seemed a Post-Human domain.
Now, sadly, even interplanetary ones are.
What about the '90s and the '00s and the '10s, as we slide toward
the edge? How will the approach of the Singularity spread across the
human world view? For a while yet, the general critics of machine
sapience will have good press. After all, till we have hardware as
powerful as a human brain it is probably foolish to think we'll be
able to create human equivalent (or greater) intelligence. (There is
the far-fetched possibility that we could make a human equivalent out
of less powerful hardware, if were willing to give up speed, if we
were willing to settle for an artificial being who was literally slow
[29]. But it's much more likely that devising the software will be a
tricky process, involving lots of false starts and experimentation. If
so, then the arrival of self-aware machines will not happen till after
the development of hardware that is substantially more powerful than
humans' natural equipment.)
But as time passes, we should see more symptoms. The dilemma felt
by science fiction writers will be perceived in other creative
endeavors. (I have heard thoughtful comic book writers worry about
how to have spectacular effects when everything visible can be
produced by the technically commonplace.) We will see automation
replacing higher and higher level jobs. We have tools right now
(symbolic math programs, cad/cam) that release us from most low-level
drudgery. Or put another way: The work that is truly productive is the
domain of a steadily smaller and more elite fraction of humanity. In
the coming of the Singularity, we are seeing the predictions of _true_
technological unemployment finally come true.
Another symptom of progress toward the Singularity: ideas
themselves should spread ever faster, and even the most radical will
quickly become commonplace. When I began writing, it seemed very easy
to come up with ideas that took decades to percolate into the cultural
consciousness; now the lead time seems more like eighteen months. (Of
course, this could just be me losing my imagination as I get old, but
I see the effect in others too.) Like the shock in a compressible
flow, the Singularity moves closer as we accelerate through the
critical speed.
And what of the arrival of the Singularity itself? What can be
said of its actual appearance? Since it involves an intellectual
runaway, it will probably occur faster than any technical revolution
seen so far. The precipitating event will likely be unexpected --
perhaps even to the researchers involved. ("But all our previous
models were catatonic! We were just tweaking some parameters....") If
networking is widespread enough (into ubiquitous embedded systems), it
may seem as if our artifacts as a whole had suddenly wakened.
And what happens a month or two (or a day or two) after that? I
have only analogies to point to: The rise of humankind. We will be in
the Post-Human era. And for all my rampant technological optimism,
sometimes I think I'd be more comfortable if I were regarding these
transcendental events from one thousand years remove ... instead of
twenty.
_Can the Singularity be Avoided?_
Well, maybe it won't happen at all: Sometimes I try to imagine
the symptoms that we should expect to see if the Singularity is not to
develop. There are the widely respected arguments of Penrose [18] and
Searle [21] against the practicality of machine sapience. In August
of 1992, Thinking Machines Corporation held a workshop to investigate
the question "How We Will Build a Machine that Thinks" [Thearling]. As
you might guess from the workshop's title, the participants were not
especially supportive of the arguments against machine intelligence.
In fact, there was general agreement that minds can exist on
nonbiological substrates and that algorithms are of central importance
to the existence of minds. However, there was much debate about the
raw hardware power that is present in organic brains. A minority felt
that the largest 1992 computers were within three orders of magnitude
of the power of the human brain. The majority of the participants
agreed with Moravec's estimate [16] that we are ten to forty years
away from hardware parity. And yet there was another minority who
pointed to [6] [20], and conjectured that the computational competence
of single neurons may be far higher than generally believed. If so,
our present computer hardware might be as much as _ten_ orders of
magnitude short of the equipment we carry around in our heads. If this
is true (or for that matter, if the Penrose or Searle critique is
valid), we might never see a Singularity. Instead, in the early '00s
we would find our hardware performance curves begin to level off --
this caused by our inability to automate the complexity of the design
work necessary to support the hardware trend curves. We'd end up with
some _very_ powerful hardware, but without the ability to push it
further. Commercial digital signal processing might be awesome,
giving an analog appearance even to digital operations, but nothing
would ever "wake up" and there would never be the intellectual runaway
which is the essence of the Singularity. It would likely be seen as a
golden age ... and it would also be an end of progress. This is very
like the future predicted by Gunther Stent. In fact, on page 137 of
[24], Stent explicitly cites the development of transhuman
intelligence as a sufficient condition to break his projections.
But if the technological Singularity can happen, it will. Even
if all the governments of the world were to understand the "threat"
and be in deadly fear of it, progress toward the goal would continue.
In fiction, there have been stories of laws passed forbidding the
construction of "a machine in the form of the mind of man" [12]. In
fact, the competitive advantage -- economic, military, even artistic
-- of every advance in automation is so compelling that passing laws,
or having customs, that forbid such things merely assures that someone
else will get them first.
Eric Drexler [7] has provided spectacular insight about how far
technical improvement may go. He agrees that superhuman intelligences
will be available in the near future -- and that such entities pose a
threat to the human status quo. But Drexler argues that we can embed
such transhuman devices in rules or physical confinement such that
their results can be examined and used safely. This is I. J. Good's
ultraintelligent machine, with a dose of caution. I argue that
confinement is intrinsically impractical. For the case of physical
confinement: Imagine yourself confined to your house with only limited
data access to the outside, to your masters. If those masters thought
at a rate -- say -- one million times slower than you, there is little
doubt that over a period of years (your time) you could come up with
"helpful advice" that would incidentally set you free. (I call this
"fast thinking" form of superintelligence "weak superhumanity". Such a
"weakly superhuman" entity would probably burn out in a few weeks of
outside time. "Strong superhumanity" would be more than cranking up
the clock speed on a human-equivalent mind. It's hard to say
precisely what "strong superhumanity" would be like, but the
difference appears to be profound. Imagine running a dog mind at very
high speed. Would a thousand years of doggy living add up to any human
insight? (Now if the dog mind were cleverly rewired and _then_ run at
high speed, we might see something different....) Most speculations
about superintelligence seem to be based on the weakly superhuman
model. I believe that our best guesses about the post-Singularity
world can be obtained by thinking on the nature of strong
superhumanity. I will return to this point later in the paper.)
The other approach to Drexlerian confinement is to build _rules_
into the mind of the created superhuman entity (Asimov's Laws). I
think that performance rules strict enough to be safe would also
produce a device whose ability was clearly inferior to the unfettered
versions (and so human competition would favor the development of the
those more dangerous models). Still, the Asimov dream is a wonderful
one: Imagine a willing slave, who has 1000 times your capabilities in
every way. Imagine a creature who could satisfy your every safe wish
(whatever that means) and still have 99.9% of its time free for other
activities. There would be a new universe we never really understood,
but filled with benevolent gods (though one of _my_ wishes might be to
become one of them).
If the Singularity can not be prevented or confined, just how bad
could the Post-Human era be? Well ... pretty bad. The physical
extinction of the human race is one possibility. (Or as Eric Drexler
put it of nanotechnology: Given all that such technology can do,
perhaps governments would simply decide that they no longer need
citizens!). Yet physical extinction may not be the scariest
possibility. Again, analogies: Think of the different ways we relate
to animals. Some of the crude physical abuses are implausible, yet....
In a Post-Human world there would still be plenty of niches where
human equivalent automation would be desirable: embedded systems in
autonomous devices, self-aware daemons in the lower functioning of
larger sentients. (A strongly superhuman intelligence would likely be
a Society of Mind [15] with some very competent components.) Some
of these human equivalents might be used for nothing more than digital
signal processing. They would be more like whales than humans. Others
might be very human-like, yet with a one-sidedness, a _dedication_
that would put them in a mental hospital in our era. Though none of
these creatures might be flesh-and-blood humans, they might be the
closest things in the new enviroment to what we call human now. (I. J.
Good had something to say about this, though at this late date the
advice may be moot: Good [11] proposed a "Meta-Golden Rule",
which might be paraphrased as "Treat your inferiors as you would be
treated by your superiors." It's a wonderful, paradoxical idea (and
most of my friends don't believe it) since the game-theoretic payoff
is so hard to articulate. Yet if we were able to follow it, in some
sense that might say something about the plausibility of such kindness
in this universe.)
I have argued above that we cannot prevent the Singularity,
that its coming is an inevitable consequence of the humans' natural
competitiveness and the possibilities inherent in technology. And yet
... we are the initiators. Even the largest avalanche is triggered by
small things. We have the freedom to establish initial conditions,
make things happen in ways that are less inimical than others. Of
course (as with starting avalanches), it may not be clear what the
right guiding nudge really is:
_Other Paths to the Singularity: Intelligence Amplification_
When people speak of creating superhumanly intelligent beings,
they are usually imagining an AI project. But as I noted at the
beginning of this paper, there are other paths to superhumanity.
Computer networks and human-computer interfaces seem more mundane than
AI, and yet they could lead to the Singularity. I call this
contrasting approach Intelligence Amplification (IA). IA is something
that is proceeding very naturally, in most cases not even recognized
by its developers for what it is. But every time our ability to access
information and to communicate it to others is improved, in some sense
we have achieved an increase over natural intelligence. Even now, the
team of a PhD human and good computer workstation (even an off-net
workstation!) could probably max any written intelligence test in
existence.
And it's very likely that IA is a much easier road to the
achievement of superhumanity than pure AI. In humans, the hardest
development problems have already been solved. Building up from within
ourselves ought to be easier than figuring out first what we really
are and then building machines that are all of that. And there is at
least conjectural precedent for this approach. Cairns-Smith [5] has
speculated that biological life may have begun as an adjunct to still
more primitive life based on crystalline growth. Lynn Margulis [14]
has made strong arguments for the view that mutualism is the great
driving force in evolution.
Note that I am not proposing that AI research be ignored or less
funded. What goes on with AI will often have applications in IA, and
vice versa. I am suggesting that we recognize that in network and
interface research there is something as profound (and potential wild)
as Artificial Intelligence. With that insight, we may see projects
that are not as directly applicable as conventional interface and
network design work, but which serve to advance us toward the
Singularity along the IA path.
Here are some possible projects that take on special
significance, given the IA point of view:
o Human/computer team automation: Take problems that are normally
considered for purely machine solution (like hill-climbing
problems), and design programs and interfaces that take a
advantage of humans' intuition and available computer hardware.
Considering all the bizarreness of higher dimensional
hill-climbing problems (and the neat algorithms that have been
devised for their solution), there could be some very interesting
displays and control tools provided to the human team member.
o Develop human/computer symbiosis in art: Combine the graphic
generation capability of modern machines and the esthetic
sensibility of humans. Of course, there has been an enormous
amount of research in designing computer aids for artists, as
labor saving tools. I'm suggesting that we explicitly aim for a
greater merging of competence, that we explicitly recognize the
cooperative approach that is possible. Karl Sims [22] has done
wonderful work in this direction.
o Allow human/computer teams at chess tournaments. We already
have programs that can play better than almost all humans. But
how much work has been done on how this power could be used by a
human, to get something even better? If such teams were allowed
in at least some chess tournaments, it could have the positive
effect on IA research that allowing computers in tournaments had
for the corresponding niche in AI.
o Develop interfaces that allow computer and network access without
requiring the human to be tied to one spot, sitting in front of a
computer. (This is an aspect of IA that fits so well with known
economic advantages that lots of effort is already being spent on
it.)
o Develop more symmetrical decision support systems. A popular
research/product area in recent years has been decision support
systems. This is a form of IA, but may be too focussed on
systems that are oracular. As much as the program giving the user
information, there must be the idea of the user giving the
program guidance.
o Use local area nets to make human teams that really work (ie,
are more effective than their component members). This is
generally the area of "groupware", already a very popular
commercial pursuit. The change in viewpoint here would be to
regard the group activity as a combination organism. In one
sense, this suggestion might be regarded as the goal of inventing
a "Rules of Order" for such combination operations. For instance,
group focus might be more easily maintained than in classical
meetings. Expertise of individual human members could be isolated
from ego issues such that the contribution of different members
is focussed on the team project. And of course shared data bases
could be used much more conveniently than in conventional
committee operations. (Note that this suggestion is aimed at team
operations rather than political meetings. In a political
setting, the automation described above would simply enforce the
power of the persons making the rules!)
o Exploit the worldwide Internet as a combination human/machine
tool. Of all the items on the list, progress in this is
proceeding the fastest and may run us into the Singularity before
anything else. The power and influence of even the present-day
Internet is vastly underestimated. For instance, I think our
contemporary computer systems would break under the weight of
their own complexity if it weren't for the edge that the USENET
"group mind" gives the system administration and support people!)
The very anarchy of the worldwide net development is evidence of
its potential. As connectivity and bandwidth and archive size and
computer speed all increase, we are seeing something like Lynn
Margulis' [14] vision of the biosphere as data processor
recapitulated, but at a million times greater speed and with
millions of humanly intelligent agents (ourselves).
The above examples illustrate research that can be done within
the context of contemporary computer science departments. There are
other paradigms. For example, much of the work in Artificial
Intelligence and neural nets would benefit from a closer connection
with biological life. Instead of simply trying to model and understand
biological life with computers, research could be directed toward the
creation of composite systems that rely on biological life for
guidance or for the providing features we don't understand well enough
yet to implement in hardware. A long-time dream of science-fiction has
been direct brain to computer interfaces [2] [28]. In fact, there is
concrete work that can be done (and has been done) in this area:
o Limb prosthetics is a topic of direct commercial applicability.
Nerve to silicon transducers can be made [13]. This is an
exciting, near-term step toward direct communcation.
o Similar direct links into brains may be feasible, if the bit
rate is low: given human learning flexibility, the actual
brain neuron targets might not have to be precisely selected.
Even 100 bits per second would be of great use to stroke
victims who would otherwise be confined to menu-driven
interfaces.
o Plugging in to the optic trunk has the potential for bandwidths
of 1 Mbit/second or so. But for this, we need to know the
fine-scale architecture of vision, and we need to place an
enormous web of electrodes with exquisite precision. If we want
our high bandwidth connection to be _in addition_ to what paths
are already present in the brain, the problem becomes vastly more
intractable. Just sticking a grid of high-bandwidth receivers
into a brain certainly won't do it. But suppose that the
high-bandwidth grid were present while the brain structure was
actually setting up, as the embryo develops. That suggests:
o Animal embryo experiments. I wouldn't expect any IA success
in the first years of such research, but giving developing brains
access to complex simulated neural structures might be very
interesting to the people who study how the embryonic brain
develops. In the long run, such experiments might produce
animals with additional sense paths and interesting intellectual
abilities.
Originally, I had hoped that this discussion of IA would yield
some clearly safer approaches to the Singularity. (After all, IA
allows our participation in a kind of transcendance.) Alas, looking
back over these IA proposals, about all I am sure of is that they
should be considered, that they may give us more options. But as for
safety ... well, some of the suggestions are a little scarey on their
face. One of my informal reviewers pointed out that IA for individual
humans creates a rather sinister elite. We humans have millions of
years of evolutionary baggage that makes us regard competition in a
deadly light. Much of that deadliness may not be necessary in today's
world, one where losers take on the winners' tricks and are coopted
into the winners' enterprises. A creature that was built _de novo_
might possibly be a much more benign entity than one with a kernel
based on fang and talon. And even the egalitarian view of an Internet
that wakes up along with all mankind can be viewed as a nightmare
[25].
The problem is not that the Singularity represents simply the
passing of humankind from center stange, but that it contradicts some
of our most deeply held notions of being. I think a closer look at the
notion of strong superhumanity can show why that is.
_Strong Superhumanity and the Best We Can Ask for_
Suppose we could tailor the Singularity. Suppose we could attain
our most extravagant hopes. What then would we ask for:
That humans themselves would become their own successors, that
whatever injustice occurs would be tempered by our knowledge of our
roots. For those who remained unaltered, the goal would be benign
treatment (perhaps even giving the stay-behinds the appearance of
being masters of godlike slaves). It could be a golden age that also
involved progress (overleaping Stent's barrier). Immortality (or at
least a lifetime as long as we can make the universe survive [9]
[3]) would be achievable.
But in this brightest and kindest world, the philosophical
problems themselves become intimidating. A mind that stays at the same
capacity cannot live forever; after a few thousand years it would look
more like a repeating tape loop than a person. (The most chilling
picture I have seen of this is in [17].) To live indefinitely long,
the mind itself must grow ... and when it becomes great enough, and
looks back ... what fellow-feeling can it have with the soul that it
was originally? Certainly the later being would be everything the
original was, but so much vastly more. And so even for the individual,
the Cairns-Smith (or Lynn Margulis) notion of new life growing
incrementally out of the old must still be valid.
This "problem" about immortality comes up in much more direct
ways. The notion of ego and self-awareness has been the bedrock of
the hardheaded rationalism of the last few centuries. Yet now the
notion of self-awareness is under attack from the Artificial
Intelligence people ("self-awareness and other delusions").
Intelligence Amplification undercuts the importance of ego from
another direction. The post-Singularity world will involve extremely
high-bandwidth networking. A central feature of strongly superhuman
entities will likely be their ability to communicate at variable
bandwidths, including ones far higher than speech or written messages.
What happens when pieces of ego can be copied and merged, when the
size of a selfawareness can grow or shrink to fit the nature of the
problems under consideration? These are essential features of strong
superhumanity and the Singularity. Thinking about them, one begins to
feel how essentially strange and different the Post-Human era will be
-- _no matter how cleverly and benignly it is brought to be_.
From one angle, the vision fits many of our happiest dreams:
a place unending, where we can truly know one another and understand
the deepest mysteries. From another angle, it's a lot like the worst
case scenario I imagined earlier in this paper.
Which is the valid viewpoint? In fact, I think the new era is
simply too different to fit into the classical frame of good and
evil. That frame is based on the idea of isolated, immutable minds
connected by tenuous, low-bandwith links. But the post-Singularity
world _does_ fit with the larger tradition of change and cooperation
that started long ago (perhaps even before the rise of biological
life). I think there _are_ notions of ethics that would apply in such
an era. Research into IA and high-bandwidth communications should
improve this understanding. I see just the glimmerings of this now,
in Good's Meta-Golden Rule, perhaps in rules for distinguishing self
from others on the basis of bandwidth of connection. And while mind
and self will be vastly more labile than in the past, much of what we
value (knowledge, memory, thought) need never be lost. I think
Freeman Dyson has it right when he says [8]: "God is what mind becomes
when it has passed beyond the scale of our comprehension."
[I wish to thank John Carroll of San Diego State University and Howard
Davidson of Sun Microsystems for discussing the draft version of this
paper with me.]
_Annotated Sources [and an occasional plea for bibliographical help]_
[1] Alfvén, Hannes, writing as Olof Johanneson, _The End of Man?_,
Award Books, 1969 earlier published as "The Tale of the Big
Computer", Coward-McCann, translated from a book copyright 1966
Albert Bonniers Forlag AB with English translation copyright 1966
by Victor Gollanz, Ltd.
[2] Anderson, Poul, "Kings Who Die", _If_, March 1962, p8-36.
Reprinted in _Seven Conquests_, Poul Anderson, MacMillan Co., 1969.
[3] Barrow, John D. and Frank J. Tipler, _The Anthropic Cosmological
Principle_, Oxford University Press, 1986.
[4] Bear, Greg, "Blood Music", _Analog Science Fiction-Science Fact_,
June, 1983. Expanded into the novel _Blood Music_, Morrow, 1985
[5] Cairns-Smith, A. G., _Seven Clues to the Origin of Life_, Cambridge
University Press, 1985.
[6] Conrad, Michael _et al._, "Towards an Artificial Brain",
_BioSystems_, vol23, pp175-218, 1989.
[7] Drexler, K. Eric, _Engines of Creation_, Anchor Press/Doubleday, 1986.
[8] Dyson, Freeman, _Infinite in All Directions_, Harper && Row, 1988.
[9] Dyson, Freeman, "Physics and Biology in an Open Universe", _Review
of Modern Physics_, vol 51, pp447-460, 1979.
[10] Good, I. J., "Speculations Concerning the First Ultraintelligent
Machine", in _Advances in Computers_, vol 6, Franz L. Alt and
Morris Rubinoff, eds, pp31-88, 1965, Academic Press.
[11] Good, I. J., [Help! I can't find the source of Good's Meta-Golden
Rule, though I have the clear recollection of hearing about it
sometime in the 1960s. Through the help of the net, I have found
pointers to a number of related items. G. Harry Stine and Andrew
Haley have written about metalaw as it might relate to
extraterrestrials: G. Harry Stine, "How to Get along with
Extraterrestrials ... or Your Neighbor", _Analog Science Fact-
Science Fiction_, February, 1980, p39-47.]
[12] Herbert, Frank, _Dune_, Berkley Books, 1985. However, this novel was
serialized in _Analog Science Fiction-Science Fact_ in the 1960s.
[13] Kovacs, G. T. A. _et al._, "Regeneration Microelectrode Array for
Peripheral Nerve Recording and Stimulation", _IEEE Transactions
on Biomedical Engineering_, v 39, n 9, pp 893-902.
[14] Margulis, Lynn and Dorion Sagan, _Microcosmos, Four Billion Years of
Evolution from Our Microbial Ancestors_, Summit Books, 1986.
[15] Minsky, Marvin, _Society of Mind_, Simon and Schuster, 1985.
[16] Moravec, Hans, _Mind Children_, Harvard University Press, 1988.
[17] Niven, Larry, "The Ethics of Madness", _If_, April 1967, pp82-108.
Reprinted in _Neutron Star_, Larry Niven, Ballantine Books, 1968.
[18] Penrose, R., _The Emperor's New Mind_, Oxford University Press, 1989.
[19] Platt, Charles, Private Communication.
[20] Rasmussen, S. _et al._, "Computational Connectionism within Neurons:
a Model of Cytoskeletal Automata Subserving Neural Networks", in
_Emergent Computation_, Stephanie Forrest, ed., p428-449, MIT
Press, 1991.
[21] Searle, John R., "Minds, Brains, and Programs", in _The Behavioral and
Brain Sciences_, v.3, Cambridge University Press, 1980. The
essay is reprinted in _The Mind's I_, edited by Douglas R.
Hofstadter and Daniel C. Dennett, Basic Books, 1981. This
reprinting contains an excellent critique of the Searle essay.
[22] Sims, Karl, "Interactive Evolution of Dynamical Systems", Thinking
Machines Corporation, Technical Report Series (published in _Toward
a Practice of Autonomous Systems: Proceedings of the First European
Cnference on Artificial Life_, Paris, MIT Press, December 1991.
[23] Stapledon, Olaf, _The Starmaker_, Berkley Books, 1961 (but from
the forward probably written before 1937).
[24] Stent, Gunther S., _The Coming of the Golden Age: A View of the End
of Progress_, The Natural History Press, 1969.
[25] Swanwick Michael, _Vacuum Flowers_, serialized in _Isaac Asimov's
Science Fiction Magazine_, December(?) 1986 - February 1987.
Republished by Ace Books, 1988.
[26] Thearling, Kurt, "How We Will Build a Machine that Thinks", a workshop
at Thinking Machines Corporation. Personal Communication.
[27] Ulam, S., Tribute to John von Neumann, _Bulletin of the American
Mathematical Society_, vol 64, nr 3, part 2, May, 1958, p1-49.
[28] Vinge, Vernor, "Bookworm, Run!", _Analog_, March 1966, pp8-40.
Reprinted in _True Names and Other Dangers_, Vernor Vinge, Baen
Books, 1987.
[29] Vinge, Vernor, "True Names", _Binary Star Number 5_, Dell, 1981.
Reprinted in _True Names and Other Dangers_, Vernor Vinge, Baen
Books, 1987.
[30] Vinge, Vernor, First Word, _Omni_, January 1983, p10.
A.O. Remizov
A BRIEF INTRODUCTION
TO SINGULARITY THEORY
Trieste, 2010
1 Lecture 1. Some useful facts from Singularity Theory.
Throughout this course all definitions and statements are local, that is, we always operate
with «suﬃciently small» neighborhoods of the considered point. In other words, we deal with
germs of functioms, maps, vector fields, etc.
1.1 Multiplicity of smooth functions and maps
One of the key notions of Singularity Theory is «multiplicity».
Definition 1:
Let f(x) : R →R be a smooth («smooth» means C∞) function, and x∗ is its critical
point, i.e., f′(x∗) = 0. Multiplicity of the function f(x) at the critical point x∗is the order of
tangency of the graphs y= f(x) and y= f(x∗) at x∗, i.e., the natural number µ is defined
by the condition
df
dµf
dµ+1f
dx(x∗) = 0, ...,
dxµ(x∗) = 0,
dxµ+1 (x∗) ̸= 0. (1.1)
If such natural number µ does not exist, then we put µ= ∞and the function f(x)−f(x∗)
is called «∞-flat» or simply «flat» at the point x∗. We also put µ= 0 for non-critical points.
Critical points with infinite multiplicity can occur, but we will deal only with finite
multiplicities. If µ= 1, then the critical point x∗ is called «non-degenerated».
Exercise 1.
Prove that any function f with µ<∞can be simplified to the form f(x) = f(x∗) ±(x−
x∗)µ+1 by means of a smooth change of the variable x (the sign ±coincides with the sign
of the non-zero derivative in (1.1)). In particular, for non-degenerated critical point we get
one-dimensional case of the Morse lemma.
Hint: Use Hadamard’s lemma.1
Multiplicity is also defined for functions of several variables x1,...,xp.
Recall that «formal series» of the variables x1,...,xp are power series
∞
cn1 ...np
xn1
1···xnp
p , (1.2)
n1+···+np=0
where n1,...,np are integer non-negative numbers, cn1 ...np are «numbers», i.e., elements of
some algebraic field (usually R or C), in this course we will always deal with R. The word
«formal» means that the series (1.2) may be nonconvergent at all points (of course, except
for the origin x1 = ···= xp = 0).
Clearly, it is possible to define the addition and multiplication of formal series similarly as
for convergent series (it’s even simpler, since we don’t need to think about the convergence).
Then we get the commutative ring and even algebra over the field R of formal series, it is
usually denoted by R[[x1,...,xp]].
In particular, for p= 1 the series (1.2) have the form
∞
cnxn
, (1.3)
n=0
1Hadamard’s lemma: in a neighborhood of 0 any smooth function f(x) : Rp →R can be presented in the form
f(x) = f(0) + x1g1(x) +···+ xpgp(x), x= (x1,...,xp),
with appropriate smooth functions gi(x). The proof can be found in many books, e.g. V.A. Zorich «Mathematical Analysis»
(it is one of the best textbooks in Calculus).
2
and the corresponding algebra is denoted by R[[x]].
Why do we need to consider formal series? At first sight, it seems that this notion does
not make sense: if the series (1.2) or (1.3) divergent they don’t correspond to any real object.
However formal series are very useful tool in many diﬀerent fields of mathematics, including
algebraic geometry.2 and diﬀerential equations3 Several examples will be given in this course.
Let f(x1,...,xp) : Rp →R be a smooth function of p variables, and x∗ is its critical
point, i.e., fxi (x∗) = 0 for all indexes i= 1,...,p. Without loss of generality assume x∗= 0
(origin in the space Rp). The function f(x1,...,xp) is connected with so-called «gradient
map» ∇f : Rp →Rp defined by the formula
∇f : (x1,...,xp)→(fx1 ,...,fxp ). (1.4)
LetAp = R[[x1,...,xp]] bethealgebraoftheformalseriesofx1,...,xp.ByI∇f denotethe
ideal in the algebra of smooth functions of pvariables generated by the functions fx1 ,...,fxp.
The ideal I∇f can be embedded in the algebra Ap of the formal series, since each smooth
function of p variables has the Taylor series at 0, which is element of Ap.
It is not hard to see that the ideal I∇f is also a vector subspace of Ap. Then it is possible
to define4 the factor-algebra Ap/I∇f, which is called the «local algebra» of the gradient
map (1.4) and the initial function f(x1,...,xp) at the point 0. Notice that the definition of
a factor-algebra includes some nuances (see below).
Remark. A factor-algebra can be constructed as follows.
Let A be an arbitrary algebra (over a field K) and I ⊂A be an ideal of A that is also a
vector subspace of A. Firstly, let’s consider Aas a ring and define the factor-ring A/I by the
standard way: A/I consists of the residue classes of all elements of A modulo the additive
subgroup I:
a+ I= {a+ b |∀b∈I}.
Secondly, we can turn the factor-ring A/I into an algebra (over the same field K) if we define
the multiplication of the elements of A/I by the elements k∈K with the rule:
k(a+ I) = ka+ I, ∀a∈A,
here we used the property kb∈I for each b∈I and k∈K, since I ⊂Ais a vector subspace.
It is not hard to see that all axoims of a vector space hold true.
Definition 2:
The number µ= dim Ap/I∇f is called the multiplicity of the function
f(x1,...,xp)
at the critical point 0 (here «dim» means the dimension of the local algebra Ap/I∇f as a
vector space). If µ= 1, then the critical point 0 is called «non-degenerated».
This definition of µis invariant (does not depend on changes of the variables x1,...,xp).
Indeed, after such change of the variables we get a new function f′ with new gradient map,
new ideal I∇f′ and new local algebra Ap/I∇f′. However it is not hard to see that Ap/I∇f′ is
isomorphic to Ap/I∇f. Hence the dimensions of both vector spaces coincide: µ′
= µ.
Exercise 2.
Prove that in the case p= 1 the definitions 1 and 2 coincide.
2R.J. Walker. Algebraic curves. – Princeton, 1950.
3V.I. Arnold. Geometrical methods in the theory of ordinary diﬀerential equations. – Springer-Verlag 1988.
4E.B.Vinberg. A Course in Algebra (Graduate Studies in Mathematics, vol. 56).
3
Solution: Let’s define the number µ by the formula (1.1). Suppose that µ < ∞(the
extremal case µ= ∞we left to the reader). Then the Taylor series of the gradient map
∇f : x →f′(x) starts with xµ. Hence any element g ∈A1 = R[[x]] can be represented
in the form g= Pµ−1 + α·∇f, where Pµ−1 is a polynomial of degree µ−1 and α ∈A1
is appropriate formal series. This representation implies that the vector space A1/I∇f is
isomorphic to the vector space of polynomials of degree µ−1. Since each polynomial of
degree µ−1 is determined by µ coeﬃcients, we get dim(A1/I∇f) = µ.
Exercise 3.
Prove that the given definition of non-degenerated critical point coincides with well-knows
definition from Calculus: the Hessian of f is not equal to zero.
Solution: The condition (Hessian of f) ̸= 0 is equivalent to the condition that the
generators fx1 ,...,fxp
of the ideal I∇f have linearly independent gradients at 0. Then any
element g∈Ap = R[[x1,...,xp]] can be written in the form
g(x1,...,xp) = c+ α1fx1 +···+ αpfxp ,
where αi ∈Ap are appropriate formal series and c = g(0). This implies dim(Ap/I∇f) = 1.
The proof of the converse statement is similar.
Exercise 4.
Calculate the multiplicity at 0 of the functions f(x,y) : R2 →R given by the following
formulas: f= x2 + y2
, f = exp (x2 + y2), f= x2 + xy+ y2
, f= x2
, f= x2 + 2xy+ y2
,
f= x2y, f= x3 + y2
, f= x4 + y2
, f= x3 + y3
.
Answer: 1, 1, 1, ∞, ∞, ∞, 2, 3, 4.
In the case µ < ∞we have the following statement (a far generalization of the Morse
lemma, which describes the partial case µ= 1).
Tougeron’s Theorem: in a neighborhood of the critical point 0 with µ < ∞there
exit smooth local coordinates that the function f(x1,...,xp) is a polynomial P(x1,...,xp)
of degree µ+ 1. Namely, the statement holds true if we put P(x1,...,xp) = the Taylor
polynomial of f(x1,...,xp) at 0 in the initial coordinates.
Further we consider functions of several variables, but all of them (except for only one)
play a role of parameters, and the multiplicity of a function is defined by this exceptional
variable, i.e., using the formula similar to (1.1).
1.2 The Division Theorem
Let F(x,y) : R ×Rp →R is a smooth function. We separate the arguments of F such that
x∈R plays a role of the «main variable», and y ∈Rp play a role of parameters. Fixing the
variables y= (y1,...,yp), we get the function f(x) of the variable xand consider the critical
points of this function.
Let T0 = (x0,y0) ∈R ×Rn be the critical point, i.e., Fx(T0) = 0. Then the multiplicity
by the variable x is defined by the following condition:
∂F
∂µF
∂x(T0) = 0, ...,
∂xµ (T0) = 0,
∂µ+1F
∂xµ+1 (T0) ̸= 0. (1.5)
As before, we put µ= 0 in the case of non-critical point.
For simplicity, we formulate the Division Theorem for the point x0 = 0. The general case
can be easily obtained using the change of variable x→x+ x0.
4
Division Theorem. In a neighborhood of the critical point T0 = (0,y0) with 0 ≤µ<∞
the function F(x,y) has the form
F(x,y) = F(0,y0) + ϕ(x,y)· xµ+1 +
µ
i=0
ai(y)xµ−i
, (1.6)
where ai(y),ϕ(x,y) are smooth functions, ϕ(x,y) ̸= 0, and ai(y0) = 0.
Firstly this theorem was established by K. Weierstrass for analytic functions of complex
variables.5 The complex analytic and real analytic variants of this theorem are often called
«Weierstrass division theorem». The smooth variant of this theorem (given above) is also
called «Malgrange division theorem» or «Mather division theorem».
I do not give the proof of this theorem, because it can be found in many books, see for
instanse:
•M. Golubitsky, V. Guillemin. Stable maps and their singularities. – Graduate Texts in
Mathematics, vol.14, Springer-Verlag, 1973.
•Th.Br¨ocker,L.Lander.DiﬀerentialbleGermsandCatastrophes.–CambridgeUniversity
Press, 1975.
The Division Theorem allows to get a lot of useful facts, which we will use in the future
lectures. In the following statement T0 is not necessarily critical point of F:
Lemma 1. Suppose that F(x,y) is a smooth function vanishing on the smooth regular
hypersurface x= γ(y) in a neighborhood of the point T0 = (x0,y0). Then
F(x,y) = (x−γ(y))·ϕ(x,y) (1.7)
where ϕ is a smooth function.
Proof. Remark that the change of variable x →x−γ(y) turns the point T0 to (0,y0)
and turns the hypersurface x= γ(y) to the hyperplane x= 0. Hence it is suﬃcient to prove
this statement for γ(y) ≡0. Also remark that it is suﬃcient to prove this statement for the
case when T0 is the critical point of F(x,y) by the variable xwith µ<∞. Indeed, if it is not
the case, we can add to the function F(x,y) the term xµ
, µ>0, and establish the equality
F(x,y) + xµ = xϕ ⇔F(x,y) = x(ϕ−xµ−1).
Thus assume that F satisfies the condition (1.5) with µ < ∞. Then from the Division
Theorem it follows that in a neighborhood of T0 the function F(x,y) has the form (1.6),
where F(0,y0) = 0 and the expression in the big brackets vanishes on the hyperplane x= 0.
Hence aµ(y) ≡0, and we get the representation F(x,y) = xϕ(x,y) in the form:
F(x,y) = x·ϕ(x,y) xµ +
µ−1
i=0
ai(y)xµ−1−i
.
Exercise 5.
Prove that for any natural n in a neighborhood of any point T0 = (0,y0) any smooth
function F(x,y) has the form
F(x,y) = f0(y) + xf1(y) +···+ xn−1fn−1(y) + xnfn(x,y), (1.8)
5
5Weierstrass K. Einige auf die Theorie der analytischen Functionen mehrerer Ver¨anderlichen sich beziehende S¨atze. –
Mathematische Werke, V. II, Mayer und M¨uller, Berlin, 1895, 135–188.
where fi are smooth functions.
Solution: Put f0(y) = F(0,y) and g(x,y) = F(x,y)−f0(y), then the function g(x,y)
vanishes on the hyperplane x= 0. Hence g(x,y) = xϕ(x,y) with a smooth function ϕ, and
we get F(x,y) = f0(y) + xϕ(x,y) ⇒(1.8) with n= 1. Applying the same reasoning to the
function ϕ(x,y), we get representation (1.8) with n= 2, etc.
Exercise 6.
Prove that if in a neighborhood of some point T0 = (x0,y0) the derivative Fx(x,y) is
smooth and vanishes on the smooth regular hypersurface x= γ(y), then the function F(x,y)
has the form
F(x,y) = f0(y) + (x−γ(y))2
·ϕ(x,y) (1.9)
with some smooth functions f0(y) and ϕ(x,y).
Solution: Using the change of variable x→x−γ(y), we reduce the problem to the case
γ(y) ≡0, i.e., hypersurface is the hyperplane x= 0. Using representation (1.8) with n= 2,
we get
F(x,y) = f0(y) + xf1(y) + x2f2(x,y).
Diﬀerentiation the above identity by x and substituting the value x = 0, we see that the
condition Fx(0,y) ≡0 is equivalent to f1(y) ≡0. Finally, after the inverse change of variable
x→x+ γ(y) we get formula (1.9).
Exercise 7.
Prove the Morse lemma:
If the smooth function F(x1,...,xm) : Rm →R has non-degenerated critical point at the
origin (0), then in a neighborhood of 0 there exit local coordinates such that
F(x1,...,xm) = F(0) + α1x2
1 +···+ αmx2
m, αi = ±1. (1.10)
Solution: For m= 1 the Morse lemma is trivial: applying two times Hadamard’s lemma
to the function F(x), we get F(x) = F(0) + x2g(x), where g(0) ̸= 0. The change of variables
x→x |g(x)|gives F(x) = F(0) + αx2, where α= sgn g(0).
Let m>1. From Linear Algebra we know that it is possible to bring the quadratic part
of the function F(x1,...,xm) to the canonical (diagonal) form using a linear change of the
variables. Since the critical point 0 is non-degenerated, all diagonal elements are non-zero:
   
a1 0··· 0
0 a2··· 0
.
.
.
.
.
.
.
.
.
.
.
.
0 0··· am
   , ai =
(0) ̸= 0.
Put x := x1 и y := (x2,...,xm), then the derivative Fx(x,y) is a smooth function and
vanishes on a smooth regular hypersurface x = γ(y). Hence the function F(x,y) has the
form (1.9), where ϕ(0,0) ̸= 0. Using the change of variable x→(x−γ(y)) |ϕ(x,y)|, we get
F(x,y) = f0(y) + α1x2, α1 = sgn ϕ(0),
where the smooth function f0(y) depends on m−1 variables y = (x2,...,xm) and 0 is
non-degenerated critical point of f0(y). Using induction on m, we get (1.10).
∂2F
∂x2
i
6
1.3 Formal series and smooth functions.
Taking the Taylor series of a smooth (recall that «smooth» means C∞) but not analytic
function f(x1,...,xp), we get a formal series, since the convergence does not follow from
smoothness. In particular, this series may converge to some analytic function which is not f
(see e.g. Exercises 8, 9).
Lemma 2. Given formal series (1.2) there exists a smooth function
f(x1,...,xp) : Rp →R (1.11)
that the Taylor series at the origin 0 coincides with the given formal series.
To prove this Lemma, we need to construct smooth functions with special properties.
Exercise 8.
Construct a smooth monotone function ϕ: R →R such that ϕ(x) = 0 for all x≤0 and
ϕ(x) = 1 for all x≥1 (see the graph of ϕ on the fig. 1a).
Solution. Define the function
f(x) =
0, x≤0,
e−1/x, x>0,
see the graph on the fig. 1b. Then the required function ϕ is given by the formula
ϕ(x) = f(x)
f(x) + f(1−x).
1−x
1−ε
Exercise 9.
For any given 0 < ε < 1 construct a smooth function ψ : R →R such that ψ(x) = 1
for |x|≤ε, ψ(x) = 0 for |x|≥1, and ψ(x) is monotone on each connected interval from
ε<|x|<1 (see the graph of ψ on the fig. 1c).
Solution. Define the function ψ by the formula
ψ(x) = ϕ
1 + x
1−ε·ϕ
,
where ϕ is the function form Exercise 8.
Question: is it possible to construct analytic functions ϕ and ψ with above properties?
Using the functions constructed above, it is possible to obtain some non-obvious and
useful results.
Exercise 10.
Prove the following statement (which is often called «Whitney Theorem»):
7
Any closed (in the standard Euclidean metric) subset of the space Rp is the set of points
defined by the equation f(x1,...,xp) = 0 for some smooth function f : Rp →R.
Hint: the proof is based on the using of multi-dimensional analog of the function ψ from
the Exercise 9:
Ψ(x) = ψ(∥x∥), where x= (x1,...,xp), ∥x∥= x2
1 +···+ x2
p. (1.12)
Spoiler. The proof can be found in the book by Th.Br¨ocker and L.Lander cited above.
By the way, Exercises 8, 9 are also taken from this book.
Proof of Lemma 2.Here I give the proof for the case p= 1, since the general case p>1
is similar, but needs a bit longer formulas. Given formal series
∞
n=0
cnxn (1.13)
construct the required function f(x) in the form
f(x) =
∞
n=0
cnxnψ(x/rn), (1.14)
where ψ is the function from Exercise 9, and rn are positive numbers (depending on cn)
such that series from the right hanf side of (1.14) and all series obtained after k times
diﬀerentiation (for any natural k) uniformly and absolutely convegre on the whole space R.
To satisfy these conditions, we can put
1
rn =
n!(1 + |cn|).
Then we have the following estimation:
∞
n=1
|cnxnψ(x/rn)|≤∞
n=1
|cn|rn
n
=
∞
n=1
|cn|
(n!(1 + |cn|))n
=
∞
n=1
1
n!
n |cn|
(1 + |cn|)n ≤∞
n=1
1
n! <∞.
In the above formula we firstly used the fact that |xnψ(x/rn)| ≤ |x|n if |x| ≤ rn, and
|xnψ(x/rn)|= 0 if |x|> rn (both statements follow from the definition of ψ). Secondly, we
used the inequality (1 + |cn|)n ≥|cn|, which holds true for n≥1 (that’s why we started the
series from 1 instead of 0).
Similarly,fortheseriesobtainedafteronediﬀerentiation,wehavethefollowingestimation:
∞
n=2
|cn(xnψ(x/rn))′|=
∞
n=2
≤∞
n=2
|cn(nxn−1ψ(x/rn) + xn/rnψ′(x/rn))|≤
|cn|rn−1
n (n+ M1) =
∞
n=2
|cn|(n+ M1)
(n!(1 + |cn|))n−1 ≤∞
n=2
where M1 = max
[−1,1] |ψ′(x)|.
The reader can prove that the similar estimations hold true for all series obtained after
k times diﬀerentiation. Hence the series from the right hand side of (1.14) converges to a
smooth function on the whole space R. Thus we need only to show that the Taylor series of
8
(n+ M1)
n! <∞,
this function f(x) at the origin coincides with (1.13), that is, f(n)(0) = n!cn. The proof of
this fact is trivial and left to the reader.
Exercise 11.
Give the proof of Lemma 2 for p>1.
Lemma 3. Any smooth function f(x,y1,...,ym) : Rm+1 →R can be represented in the
form
f(x,y) = f1(x2,y) + xf2(x2,y), y= (y1,...,ym), (1.15)
where f1 and f2 are smooth functions.
Notice that the representation (1.15) is obvious for polynomials, formal series and analytic
functions. Indeed, it is suﬃcient to write the Taylor series by the variable x(this means that
we consider y1,...,ym as parameters and xas the unique variable) and collect the monomilas
xn with even n and odd n. The validity of this operation (in the case of analytic functions)
follows from the absolute convergence of the corresponding power series.
Proof.Igivetheproofform= 0,thecasem>0 issimilar(somediﬀerencesareremarked
below). Clearly, any smooth function f(x) = fev(x) + fod(x), where fev(x) and fod(x) are
even and odd smooth functions, respectively. Indeed, put
fev(x) = f(x) + f(−x)
2 , fod(x) = f(x)−f(−x)
2.
Clearly, any odd smooth function fod(x) has the form fod(x) = xg(x), where g(x) is an even
smooth function. To prove this claim, we can use Hadamard’s lemma. Thus it is suﬃcient
establish the representation
f(x) = f1(x2) (1.16)
for even smooth functions.
Since f(x) = f(|x|), equality (1.16) holds if and only if f1(ξ) = f(√ξ) for all ξ ≥0. Thus
f1(ξ) = f( ξ), ξ ≥0,
arbitrary, ξ <0,
The only condition is required: the function f1(ξ) must be smooth on the whole R. If such
function f1 : R →R exists, the Lemma is proved.
The function f1(ξ) = f(√ξ) defined on the semiaxis ξ ≥0 is smooth at all points ξ >0.
Let us prove that this function has right-hand side derivatives of any order nat ξ = 0. From
Hadamard’s lemma we get
f(x) = c0 + c1x2 +···+ cnx2n + x2n+2g(x), (1.17)
where g(x) is a smooth even function. The expression (1.17) does not contain monomials of
odd degrees, since the function f(x) is even. Substituting x= √ξ in (1.17), we get
f1(ξ) = c0 + c1ξ+···+ cnξn + ξn+1g( ξ). (1.18)
It is not hard to show (we left it to the reader) that function (1.18) has the right-hand side
derivatives f1
(n)
+ of any order ≤n at the point ξ = 0.
Thus it is suﬃcient to define the function f1(ξ) on the semiaxis ξ < 0 such that it is
smooth and its left-hand side derivatives at ξ = 0 exist and coincide with f1
(n)
+ . In other
words, we have the formal series
∞
f1
(n)
+ (0)
n! , (1.19)
n=0
cnξn
, where cn =
9
and need to find a smooth function f1(ξ) that its Taylor series at ξ = 0 coincides with (1.19).
From Lemma 2 it follows that such function exists.
In the case m > 0 we separate the arguments of f(x,y1,...,ym) such that x plays a
role of the «main variable», and y = (y1,...,ym) play a role of parameters. The words
«even» and «odd» mean even and odd by the variable x. To establish the representations
fod(x,y) = xg(x,y) and (1.17), we can use representation (1.8) from Exercise 5.
Using the same reasonings as for m= 0, we get formal series (1.19), where the coeﬃcients
cn smoothly depend on y. Hence we need to find a smooth function f1(ξ,y) that its Taylor
series by the variable ξat ξ = 0 coincides with given formal series. To construct this function,
we can apply Lemma 2 with p= 1 (here x is the unique variable, y is a parameter).
For the reader familiar with Fourier series, it is possible to give another proof of Lemma 3.
Second Proof of Lemma 3. According to the previous reasonings, it is suﬃcient to
prove the representation (1.16) for smooth even functions and x∈[−π,π].
Expanding a smooth even function f(x) in Fourier series, we get
f(x) = c0
2 +
∞
1
cncos nx, where cn =
π
π
n=1
−π
f(x) cos nxdx. (1.20)
Fourierseries(1.20)absolutelyanduniformlyconvergestof onthesegment[−π,π].Moreover,
theseriesobtainedfrom(1.20)afterktimesdiﬀerentiation,absolutelyanduniformlyconverge
to the function f(k)(x) on the segment [−π,π]. Using the Taylor seires of cos, we can replace
the functions cos nx in (1.20) by the corresponding power series.
Finally, we get the power series, which contains the monomials only of even degrees and
absolutely and uniformly converges to f on the segment [−π,π]:
f(x) =
∞
n=0
αnx2n
,−π≤x≤π.
The above series gives the required representation f(x) = f1(x2), where the function f1 is
defined on the segment [−π2,π2] as a sum of absolutely and uniformly convergent series
f1(ξ) =
∞
n=0
αnξn
,−π2 ≤ξ ≤π2
.
10
2 Lecture 2. Implicit Diﬀerential Equations and Singularities of
Plane Curves.
In this lecture we consider Implicit Diﬀerential Equations from the Singularity Theory
viewpoint. The basic step is «lifting» of the equation from the phase plane to a sufrace in
3-dimensional projectivized tangent bundle (this construction was invited by Poincar´e and
similar to the introduction of the Riemann surface for a multivalued function of a complex
variable on which this function becomes single-valued).
Singularities of plane curves appear when after the projection of the integral curves of
the field defined on this sufrace to the phase plane.
2.1 Implicit Diﬀerential Equations: Lifting
An Implicit Diﬀerential Equation is a diﬀerential equation which is not solvable for the
derivative, that is,
dy
F(x,y,p) = 0, where p=
dx. (2.1)
Suppose that F is a smooth function («smooth» means C∞) and the equation F = 0 defines
a regular surface F in the 3-dimensional space J1 with coordinates (x,y,p), that is, 1-jet
space of functions y= y(x).
Let γ be the integral curve of equation (2.1), then its 1-graph γ ⊂F . This means that
the curve γ is tangent to the plane Fxdx+Fy dy+Fpdp= 0 at each point. From the relation
p= dy/dx it follows that γ is also tangent to the plane pdx−dy = 0, which is called the
contact plane.
Exercise 1.If the field on the contact planes pdx−dy= 0 (defined in the whole space J1)
was integrable, then there was a family of smooth surfaces filling the space J1 such that the
contact planes are tangent to these surfaces. Then 1-graphs of the integral curves of (2.1)
were the intersections of F with the surfaces of this family. But it is not the case: prove that
the field of the contact planes is not integrable.
Hint: use the Frobenius Theorem.6
The curve γ is the 1-graph of some solution of equation (2.1) if and only if at each point
it is tangent to both planes: Fxdx+ Fy dy+ Fpdp= 0 and pdx−dy= 0, i.e., it is tangent to
their intersection. An intersection of two planes in 3-dimensional space is a line or a plane
(if they coincide). The last case has codimension 2, since it is defined by two equations:
Fp = 0, Fx + pFy = 0. (2.2)
Generically, equations Fp = 0, Fx + pFy = 0, F = 0 are independent (this means that
the gradients of the functions Fp, Fx + pFy, F at the given point are linearly independent),
hence the points of F where the tangent and contact planes coincide, are isolated on F.
Exercise2.FindthesetofthepointsofF wherethetangentandcontactplanescoincide,
for the following functions: F= p2
−x, F= f(p)−xp+ y and F = (p+ αx)2
−y, where α
is a real parameter.
Remark 1. The notions «genericity», «generic property», «generic case» must be used
careful. The reader who solved the previous exercise, saw that there exist equations that
such points on F are not isolated. The formal definition of «genericity» needs «Whitney»
(or «fine») topology in the space C∞
.
6See e.g.: V.I. Arnold «Geometrical methods in the theory of ordinary diﬀerential equations» or Ph. Hartman «Ordinary
Diﬀerential Equations».
11
We say that the objects from some fixed class C have the property P in «generic case»
if the following two conditions hold. Firstly, if some object ϑ1 ∈C satisfies the property P
then all objects ϑ∈C suﬃciently close to ϑ1 also satisfy P. Secondly, if some object ϑ2 ∈C
does not satisfy P then there exists ϑ∈C arbitrarily close to ϑ2 which satisfies P. In other
words, the property P is «stable» (holds true under any suﬃciently small perturbations) and
each object ϑ∈C can be embedded into the subset CP = {ϑ∈C|P holds true}by means
of an arbitrarily small perturbation. This means that the subset CP is open and dense in C
with some topology.
In our case we deal with class C∞ of smooth functions, and «Whitney» (or «fine»)
topology is what we need. Roughly speaking, in Whitney topology two functions are «close»
to each other if their values and the values of their derivatives are «close». The reader who
needs the exact definition, is referred to the books:
•M. Golubitsky, V. Guillemin. Stable mappings and their singularities. – Graduate Texts
in Mathematics, vol.14, Springer-Verlag, 1973.
•Th.Br¨ocker,L.Lander.DiﬀerentialbleGermsandCatastrophes.–CambridgeUniversity
Press, 1975.
ThusatallthepointsofthesurfaceF exceptforthepointsoftheset(2.2)theintersection
of the tangent and contact planes defines a direction field on F . This direction field is called
«lifted field» and this construction7 is called «lifting» of equation (2.1) to the surface F.
The relationship between the lifted field and initial eqiation (2.1) is obvious: 1-graphs of
the solutions of (2.1) are the integral curves of the lifted field. Conversely, the solutions of
equation (2.1) are projections of the integral curves of the lifted field onto the (x,y)-plane
along the p-axis.
The direction field defined by equation (2.1) on the (x,y)-plane is multivalued, the lifted
fields on the surface F is single-valued. This is the sense of lifting. Of course, we pay for this
simplification: the phase space becomes a surface insted of a plane, and we have to consider
the projection of the surface on the plane. The last circumstance explains appearance of
sungularities of the solutions of equation (2.1).
To analize the integral curves of the lifted direction field, it is convenient to express it
through a vector field. This means that we define the line l(at each point) through the basis
vector of l. Of course, this correspondence is not one-to-one: it is possible to choose infinite
number of basis vectors on a line. Formally, one can say that a direction field is a class of
7It was invited by Poincar´e in his third «M´emoire sur les courbes d´efinies par les ´equations diﬀ´erentielles». This approach
allowed him to create the qualitative theory of Implicit Diﬀerential Equations that is essentially diﬀerent from the previous
analytic works of Lagrange, Cauchy, Briot, Bouquet, and others.
12
vector fields modulo a scalar-valued factor (i.e., each vector field of this class diﬀers from
each other by multiplying by a scalar-valued function). The vector field corresponding to the
lifted direction field is also called «lifted».
Intersection of the tangent and contact planes corresponds to the system of equations
Fxdx+ Fy dy+ Fpdp= 0
(2.3)
pdx−dy= 0.
Theseequationsareconsideredwithrespecttothevariablesdx,dy,dp,whicharecomponents
of the required vector field. This system is linear and homogeneous with respect to these
variables.8
System (2.3) defines the diﬀerentials dx,dy,dp up to a common factor. This is algebraic
descriptionofthefactthatthevectorfieldcorrespondingtothegivendirectionfieldisdefined
up to a scalar factor. Substituting the expression dy= pdx in the first eqiation of (2.3), we
get
(Fx + pFy) dx+ Fpdp= 0.
Thie yields the formula for the lifted vector field:
˙
x= Fp,˙
y= pFp,˙
p=−(Fx + pFy). (2.4)
Remark2.Forthereaderunfamiliarwithwritingvectorfieldsinsuchform(assystemsof
diﬀerential equations) I have to explain that the dot over a symbol here means diﬀerentiation
by some additional parameter τ, which plays a role of time. Since the right hand sides of
the equations do not contain τ, this system is autonomous. Any autonomous system defines
a vector field in the phase space (the components of this vector field are right hand sides of
the equations). Conversely, any vector field defines an autonomous system.
Exercise 3.
How the freedom of choice of the lifted vector fields is connected with the parameter τ?
Answer: Multiplication of vector field (2.4) by the scalar function µ(x,y,p) corresponds
to the change of variable τ →t defined by the equation˙
t= µ−1(x,y,p), where the dot over
a symbol means diﬀerentiation by τ.
Using the lifting, we passed from equation (2.1) to the lifted direction field on F , which
can be defined through vector field (2.4). The integral curves of (2.4) are 1-graphs of the
solutions of (2.1). To get the graphs of the solutions, we need to make projection on the
(x,y)-plane along the p-axis. The lifted direction field is defined at all points of the surface F
except for the point (2.2), which are singular points of the vector field (2.4).9 Geometrically,
such points are defined by intersection of two sets:
K= {F= Fp = 0} and L= {F= Fx + pFy = 0},
which are called the «criminant» and the «inflection curve» of equation (2.1), respectively.
In the case of generic equation (2.1) the sets K and L are smooth curves on the surface
F , which intersect only at isolated points. However in some special cases they even may
coincide (see e.g. Exercise 2).
8Systems of linear homogeneous equations on diﬀerentials of variables are named «Pfaﬃan systems» after Johann Friedrich
Pfaﬀ. Pfaﬃan system is a representation of a standard diﬀerential equations in symmetrical form: all variables in Pfaﬃan
systems have «equal righs». When we use the notation dy/dx, we suggest that the variable x is distinguished (it is called
«independent»). From geometrical viewpoint, the diﬀerence between the Pfaﬃan system and corresponding system of ordinary
diﬀerential equations is diﬀerence between homogeneous and non-homogeneous coordinates in the tangent space= «space of
diﬀerentials». Pfaﬃan systems define fields of subspaces, which are called «distributions».
9Recall that singular points of a vector field are the point where this field is equal to zero.
13
Exercise 4.
Explain the geometrical sense of the curves K and L (which explains their names).
Hint: For the criminant K consider the projection of the surface F on the (x,y)-plane
along the p-axis. For the inflection curve L consider the second-order derivative
d2y
dp
=
dx2
dx
of the solution of equation (2.1) taking into account formula (2.4).
Exercise 5.
Draw the surface F , the integral curves of the lifted field and their projection on the
(x,y)-plane for the following equations: p2
−1 = 0, p2 + x = 0, p3 + x = 0, p2
−4y = 0,
p2
−xp+ y= 0.
Exercise 6.
Suppose that the surface F is homeomorphic to a sphere. It is possible that K= ∅or
L= ∅or K ∩L= ∅?
Hint: Use Poincar´e–Hopf index theorem (the reader unfamiliar with this theorem can
found the statement below).
The projection of the criminant K on the (x,y)-plane along the p-axis is calles the
«discriminant curve» of the equation. (In the case when F(x,y,p) is a polynomial of p, the
discriminant curve is given by the equation D= 0, where D is the discriminant of F by p).
Remark that a point of the discriminant curve can correspond to several diﬀerent points
of the surface F which belong to the preimage of the projection. Moreover, some of these
points can not belong to the criminant K.
Remark 3. A close geometric interpretation of diﬀerential equations was suggested by
A. Clebsch, it is based on his «theory of connexes».
Using the modern terminology, we can say that Clebsch considered the tangent bundle
of the (x,y)-plane with homogeneous coordinates and treated a diﬀerential equation as a
connection between the points of the (x,y)-plane and the points of the projectivized tangent
bundle. By the «connex» of equation (2.1) he meant the field of tangent planes to the surface
F . He also defined the «principal connex», which is the field of contact planes common for
all such equations.
Clebsch put in correspondence to each diﬀerential equation its «principal concindence»:
by his own definition, it is the common things which has the connex of a given equation with
the principal connex. In fact, this concept corresponds to the intersection of the fields of
tangent and contact planes, i.e., to the lifted field. However, this terminology turned out to
be not very convenient and was forgotten some time after.
Remark 4. The method of lifting invited by Poincar´e, led him to studying diﬀerential
equations (vector fields) on manifolds.
In particular, Poincar´e considered the problem on the distribution of singular points
of a vector field on a 2-manifold and proved a remarkable topological result: if a smooth
vector field on a smooth compact orientable 2-manifold has only isolated singular points (for
exmaple, n nodes, s saddles, and f focuses), then the sum of their indexes (in our example:
n+ f−s) for any such a field is the same and is equal to the Euler characteristic of this
manifold. In 1926 this result was generalized by Hopf for manifolds of any finite dimension
(Poincar´e–Hopf index theorem).
14
2.2 Legendre transformation
The «Legendre transformation» (or «Legendre transform») is the automorphism (x,y,p)→
(X,Y,P) of the space J1 given by the formula
x= P, p= X, y+ Y= xp= XP. (2.5)
Applying the Legendre transformation to equation (2.1) (this means that we substitute the
expressions for the variables x,y,p through X,Y,P), we get another equation:
F∗(X,Y,P) := F(P,XP−Y,X) = 0, (2.6)
which is called «dual equation» for (2.1).
Exercise 7. Prove that:
The Legendre transform is a global diﬀeomorphism of the space J1
.
The Legendre transform is an involution, i.e., it is its own inverse.
The Legendre transform turns the diﬀerential 1-form pdx−dy to−(PdX−dY).
The Legendre transform turns the integral curves of equation (2.1) to the integral curves
of dual equation (2.6), and back.
The last property (correspondence of the integral curves) sometimes can be used for
solving Implicit Diﬀerential Equations.10 Indeed, if the dual equation (2.6) can be integrated
easierthan(2.1)anditsgeneralsolutionisY = Φ(X,c),wherecistheconstantofintegration,
then the general solution of initial equation (2.1) can be written in the parametric form
x= ΦX(p,c), y= pΦX(p,c)−Φ(p,c),
where p is the parameter.
Exercise 8.
Using the Legendre transform, solve the equations: p2
= x, ep = x, cos p= x, pep = x,
p3 + yp+ x= 0.
The reader who solved these equations saw that the criminants of the dual equations
are empty (and the inflection curves of the initial equations are also empty). This is not an
accidental coincidence. Indeed, the criminant and the inflection curve are connected by the
dual relation:
Exercise 9.
Prove that the criminant of the initial equation is the inflection curve of the dual equation,
and vice versa.
The Legendre transformation can be applied not only to integral curves of diﬀerential
equations, but to all planar curves which have 1-graphs.
Indeed, let γ be an integarl curve on the (x,y)-plane and γ is its 1-graph. Since the
curve γ belongs to the space J1, the Legendre transform turns it to another curve γ∗ in J1
.
The projection of γ∗ on the (X,Y)-plane along the P-axis is a planar curve γ∗, which is
the image of γ under the Legendre transform. This construction can be illustrated by the
following diagramm:
(x,y,p) Legendre
−−−−−→(X,Y,P)
 
 
(x,y)−−−→ (X,Y)
10This method (as any concrete method of integration) is useful only for some class of such equations. Applications of this
method for solving equations are described in the well-known handbook by Kamke on ordinary diﬀerential equations, some
examples are also in: J.W. Bruce, P.J. Giblin. Curves and Singularities (Cambridge University Press, 1984).
15
The curve γ∗ is called «dual» to the curve γ.
Exercise 10.
Find the dual curves to a straight line, parabola, cubic parabola and circle.
Exercise 11.
Suppose that γ is a smooth regular curve on a plane («regular» means that there exists
a smooth parametrization of γ that the velocity never vanishes). Prove that the dual curve
γ∗ is regular at the points corresponding to the points of γ with non-zero curvature.
Remark 5.
The Legendre transformation can be defined in multi-dimensional case and applied to
partial diﬀerential equations.11
2.3 Implicit Diﬀerential Equations: Regular and Singular points
The local phase portrait of the ordinary diﬀerential equation p= f(x,y) with a smooth
function f at any point (x0,y0) is very simple: the family of the integtal curves is locally
diﬀeomorphic to a family of straight lines. For instance, in a neighborhood of any point
(x0,y0) the equation p= f(x,y) can be brought to the form p = 0 with help of a smooth
diﬀeomorphism of the (x,y)-plane:
The main question which we want to study in this mini-course is: how the local phase
portraits of equation (2.1) look like? The reader who solved Exercise 5, saw that the local
phaseportraitsofImplicitDiﬀerentialEquationsarediﬀerent,someofthemarenotsmoothly
equivalent(andevennottopologicalyequivalent).Indeed,itissuﬃcienttocomparethephase
portraits of the equations p2
−1 = 0, p2
−x= 0, p2
−4y= 0 in a neighborhood of the origin:
Moreover, the equation p2
−x = 0 shows that even individual integral curve of Implicit
Diﬀerential Equations may have singularities (such phenomena never occurs for the ordinary
diﬀerential equation p= f(x,y)). The question we study in this lecture is: what sort of
singularities the integral curves of equation (2.1) may have? Thus in this lecture we will deal
only with individual integral curves, not the phase portraits.
11R. Courant, D. Hilbert. Methods Of Mathematical Physics. – New York-London, 1962.
16
The appearance of the singularities of the integral curves is connected with so-called
«singular points» of equation (2.1).
The point T0 = (x0,y0,p0) of the surface F is called «singular point» of equation (2.1)
if Fp(T0) = 0. Otherwise T0 is called «regular point» of this equation. Using the previous
notations, we can say that T0 is singular if T0 ∈K , and T0 is regular if T0 ∈F \K . The
geometric sense of this definition is clear: the singular points of equation (2.1) are critical
points of the projection π: F →(x,y) along the p-axis.
By Implicit Function Theorem, in a neighborhood of any regular point T0 equation (2.1)
is equivalent to equation p= f(x,y) with a smooth function f. Hence we can apply to this
equation all standard theorems, which guarantee existence, uniqueness and smoothness of
solution.12
Now let T0 be the singular point of equation (2.1), hence the Implicit Function Theorem
is not applicable. What can we say about the lifted vector field (2.4) at the point T0? Clearly,
there are two diﬀerent cases: T0 ∈K \L and T0 ∈K ∩L . The singular points of the first
kind we call «proper», and the singular points of the second kind we call «improper».
At the proper points lifted vector field (2.4) in non-zero and vertical,13 since Fp(T0) = 0
and Fx + pFy(T0) ̸= 0. At the improper points lifted vector field (2.4) in zero, that is, they
are also the singular point of the lifted vector field.
2.4 Singularities of the integral curves
In the rest part of the lecture we deal only with proper singular points.
By the standard Existence and Uniqueness Theorem, for each proper singular point T0
there exists a unique smooth integral curve γ of field (2.4) that passes through T0. Hence
the projection γ= π(γ) on the (x,y)-plane is a unique solution of equation (2.1) with the
initial condition y(x0) = y0, y′(x0) = p0. Since the projection π: F →(x,t) at the point T0
is not regular, the image π(γ) is not a regular curve. What type of singularity do it have?
To answer this question, write the smooth curve γ in the parametric form:
γ(τ) : x= ϕ(τ), y= ψ(τ), p= ϑ(τ), (2.7)
where ϕ(τ),ψ(τ),ϑ(τ) are smooth functions, γ(0) = T0.
It is convenient to use the notation G:=−(Fx + pFy). Then
˙
˙
˙
ϕ(0) = Fp(T0) = 0,
ψ(0) = pFp(T0) = 0,
ϑ(0) = G(T0) ̸= 0. (2.8)
This shows that curve (2.7) is regular (we can take the variable p as the parameter on
this curve) and the point τ = 0 is critical for the functions ϕ(τ),ψ(τ). Suppose that the
multiplicity µ of ϕ(τ) at this critical point is finite. Let n= µ+ 1, then
˙
ϕ(0) = 0, ..., ϕ(n−1)(0) = 0, ϕ(n)(0) ̸= 0. (2.9)
By L⃗
V denote the diﬀerential operator
∂
∂
L⃗
V = Fp
∂x + pFp
∂y + G ∂
∂p
12Remark that we always consider C1-smooth solutions, otherwise our reasonings are not correct. For example, for the
diﬀerentiable but not continuously diﬀerentiable solutions the Implicit Function Theorem is not applicable. Fortunately, in the
case of one-dimensional Implicit Diﬀerential Equations such solutions do not exist; see the textbook: I.G. Petrovskii. Lectures
on the theory of ordinary diﬀerential equations. However it is necessary to remember that such solutions may exist in the case
of multidimensional Implicit Diﬀerential Equations; see the paper: A.F. Filippov. Uniqueness of the solution of a system of
diﬀerential equations not solved with respect to the derivatives (Diﬀer. Equ. 41 (2005), no.1, 90–95).
13By the «vertical» direction in the (x,y,p)-space we shall mean the direction of the p-axis.
17
corresponding to vector field (2.4). Then for any natural k we have ϕ(k+1)(0) = Lk
V(Fp) T0.
⃗
Then
˙
ϕ(0) = Fp T0
= 0,¨
ϕ(0) = L⃗
V(Fp) T0 = (FpFxp + pFpFyp + GFpp) T0
= GFpp T0. (2.10)
Since G(T0) ̸= 0, we have Fpp(T0) ̸= 0 ⇔n= 2. If Fpp(T0) = 0, then continue diﬀerentiation:
ϕ(3)(0) = L2
V(Fp) T0
⃗
= G ∂
∂p(FpFxp + pFpFyp + GFpp) T0
= G2Fppp T0.
Exercise 12. Prove that if ϕ(k+1)(0) = Lk
V(Fp) T0
⃗
= 0 for all k<l, then
ϕ(l+1)(0) = Ll
V(Fp) T0
⃗
= Gl∂l+1F
∂pl+1 T0
. (2.11)
Hint: Use the induction on l with the basis given by (2.10).
Thus we have n = µ+ 1, where µ is the multiplicity of the function F(x,y,p) by the
variable p at the critical point T0 (see formula (1.5) from the previous lecture, where x is
replaced by p). The number nis the main factor which defines the type of singularity of the
integral curve γ at the point (x0,y0).
To simplify the further reasonings, choose the coordinates on the (x,y)-plane such that T0
is the origin of J1. For example, we can make the translation bringing (x0,y0) to the origin
of the plane and the linear transformation y →y−p0x. Thus from now we always assume
T0 = 0.
Exercise 13. Prove that the multiplicity of the function ψ(τ) at the critical point τ = 0
is equal to n, i.e.,
˙
ψ(0) = 0, ..., ψ(n)(0) = 0, ψ(n+1)(0) ̸= 0. (2.12)
Using formulas (2.9) and (2.12) and Hadamard’s lemma, we can present our curve in the
form
γ(τ) : x= τnϕ(τ), y= τn+1ψ(τ), (2.13)
where ϕ(τ) and ψ(τ) are smooth fucntions non-vanishing at τ = 0.
Formula (2.13) allows to understand how the curve γ looks like in a neighborhood of the
origin, but it can be further simplified. The first step is as follows.
Exercise 14.
Prove that using a regular change of the parameter τ and linear change of the variables
x and y in (2.13) we can obtain ϕ(τ) = 1 and ψ(τ) = 1 + χ(τ) or ϕ(τ) = 1 + χ(τ) and
ψ(τ) = 1, where χ(τ) is a smooth function and χ(0) = 0.
Remark 6. Formula (2.13) with ϕ(τ) = 1 and ψ(τ) = 1 + χ(τ) allows to write the
1
curve γ is the form y= y(x). Indeed, we have τ = x
n and can substitute this expression in
y= τn+1(1 + χ(τ)). If the function F(x,y,p) in equation (2.1) is analytic, then the functions
1
ϕ(τ) and ψ(τ) are also analytic, and this procedure gives y= h(x
n ), where h is an analytic
function, i.e., we have a convergent power series of x, where the power takes not only integer,
but also rational values: (n+ i)/n, i = 0,1,2,... Such series are called «Puiseux series» or
«Newton–Puiseux series».14
Let’s forget (for several minutes) about singular points of equation (2.1) and consider the
regular points lying on the inflection curve of this equation, but not on the criminant. Let
14Power series with fractional powers were used by Newton (1671) for the presentation of algebraic curves with branches.
More detailed studying of such series were given by Franch mathematician Victor Alexandre Puiseux (1850).
18
T1 = (x1,y1,p1) be such a point: T1 ∈L \K . What can we say about the integral curve
passing through T1?
Obviously, there exists a unique integral curve of the lifted field (2.4) passing through T1.
The projection of this curve on the (x,y)-plane is the smooth solution of (2.1), which can
be written is the form
y(x) = y1 + p1(x−x1) + f(x−x1), f(0) = f′(0) = f′′(0) = 0, (2.14)
where f is a smooth function and f′′(0) = 0, since the second-order derivative y′′(x) = G/Fp
vanishes at T1.
Let m≥2 be the multiplicity of the function f(x) at the origin:
f′(0) = 0, ..., f(m)(0) = 0, f(m+1)(0) ̸= 0. (2.15)
If m is even, then (x1,y1) is the inflection point of the curve (2.14), this explains the name
«inflection curve».
The reader should notice that the number n of the solution of the initial equation at the
proper singular point T0 is connected with the number mof the solution of the dual equation
at the corresponding regular point T1, since the criminant and the inflection curve of dual
equations are connected with the Legendre transformation (Exercise 9).
Exercise 15.
Prove that n = m. In particular, the cusp of the semicubic parabola corresponds to the
cubic inflection point on the dual curve.
Exercise 16.
Draw the integral curves of the equations from Exercise 8 and the dual equations.
Exercise 17.
Wesawthatanyintergalcurveofequation(2.1)passingthroughthepropersingularpoint
0 with the number n = µ+ 1, where µ is the multiplicity of the function F(x,y,p) by the
variable p, can be presented in the form (2.13). Prove the inverse statement: for any curve
γ given by formula (2.13) with any smooth functions ϕ(τ) and ψ(τ) there exists diﬀerential
equation (2.1) such that γ is its integral curve.
Solution: Apply the Legendre transformation to the curve γ, let γ∗ be the dual curve on
the (X,Y)-plane, see formula (2.5). From the results obtained above it follows that γ∗ has
the form Y= f(X), where f is a smooth function that satisfies (2.15) with m= n. Clearly,
γ∗ is the integral curve of the diﬀerential equation P= f′(X), where P= dY/dX. Now
apply the Legendre transformation to this diﬀerential equation P= f′(X). Then we get the
dual equation f′(p)−x= 0, and γ is the integral curve of f′(p)−x= 0.
The next natural question is: how to bring the curve given by formula (2.13) in a
neighborhood of the origin to a more simple from using smooth changes of the coordinates
x,y? For example, is it possible to bring (2.13) to the simplest form x = τn, y= τn+1? In
other words, we want to establish smooth local normal forms of such curves. By #n define
the number of equivalence classes for given n.
Exercise 18.
Prove that #2 = 1, i.e., for any curve given by formula (2.13) with n= 2 there exists a
smooth local change of the variables x,y bringing this curve to the form
x= τ2, y= τ3 (2.16)
in a neighborhood of the origin.
19
Solution: Take formula (2.13) with n = 2 and the functions ϕ(τ) = 1, ψ(τ) = 1 + χ(τ),
where χ(0) = 0 (see Exercise 14). Using Lemma 3 from the Lecture 1, we can present the
function χ(τ) in the form χ(τ) = χ1(τ2) + τχ2(τ2), where χ1,χ2 are smooth functions. Then
y= τ3(1 + χ1(τ2)) + τ4χ2(τ2) = τ3(1 + χ1(x)) + x2χ2(x), and the change of variable
y−x2χ2(x)
y→
1 + χ1(x)
brings the curve to the required form (2.16) in a neighborhood of the origin.
Exercise 19.
Prove that #3 = 1, i.e., for any curve given by formula (2.13) with n= 3 there exists a
smooth local change of the variables x,y bringing this curve to the form
x= τ3, y= τ4 (2.17)
in a neighborhood of the origin.
Solution: Take formula (2.13) with n = 3 and the functions ϕ(τ) = 1, ψ(τ) = 1 + χ(τ),
where χ(0) = 0. Using Hadamard’s lemma m+ 1 times, we get
x= τ3, y= τ4(1 + χ1τ +···+ χmτm + O(τm+1)). (2.18)
Step One: kill the monomial τ5. Clearly, it is suﬃcient to do this in the case χ1 = 1,
because any other χ1 ̸= 0 can be simplified to 1 by means of a linear change of the parameter
τ and scalings of x and y. Notice that the monomials τi with i>5 do not influence on this
procedure. Hence it is suﬃcient to kill the monomial τ5 for the curve
γ1(τ) : x= τ3, y= τ4 + τ5
.
The change of variable x→x+ αy with α=
3
4 brings the curve γ1 to the form
γ1(τ) : x= τ3 + α(τ4 + τ5), y= τ4 + τ5
.
After that make the change of the parameter τ →t by the formula t3 = τ3 + α(τ4 + τ5).
Then we obtain
γ1(t) : x= t3, y= ϑ4(t) + ϑ5(t),
where τ = ϑ(t) is the inverse function to t= τ(1 + α(τ + τ2))1
3 . It is not hard to show
that in a neighborhood of the origin the function ϑ is smooth and ϑ(t) = t−t2/4 + O(t3).
Substituting this expression in the equality y= ϑ4(t) + ϑ5(t) and collecting similar terms,
we get y= t4 + O(t6), i.e., the monomial τ5 is killed.
Step Two. Consider curve (2.18) with χ1 = 0:
x= τ3, y= τ4(1 + χ2τ2 +···+ χmτm + O(τm+1)), (2.19)
and show that we can kill all the monomials τi with i > 5. Remark that such monomials
can be represented in the form τi = xi1 yi2 + O(τi+1) with integer i1,i2. For instance,
= x2, τ7
= xy+ O(τ8), τ8
= y2 + O(τ9), τ9
τ11
= xy2 + O(τ12), τ12
= x3, τ10
= x2y+ O(τ11),
= x4, τ13
= x3y+ O(τ14), etc.
τ6
Hence using the substitution
y→y+ α6x2 + α7xy+ α8y2 + α9x3 + α10x2y+ α11xy2 + α12x4 + α13x3y+··· (2.20)
20
with the appropriate coeﬃcients αi, we can kill all the monomials τi
, i= 6,7,8,...Namely,
each monomial αixi1 yi2
, 3i1 + 4i2 = i, i > 5, in (2.20) kills the monomial τi in (2.18) and
does not change the monomials of degrees <i.
Since we need to kill all the monomials τi with i>5, the right hand side of (2.20) contains
an infinite number of terms, i.e., we get a formal series of x,y. If this series converges in a
neighborhood of the origin, then formula (2.20) defines an analytic change of variable, which
brings curve (2.19) to the required form (2.17). But in general, this is not the case: the
obtained formal series may diverge at all points (except for the origin). To overcome this
problem, we can use Lemma 2 form the Lecture 1.
Step Three. Let f(x,y) be the smooth function such that its Taylor series at the origin
coincides with formal series (2.20). Then the change of variables y →y + f(x,y) brings
curve (2.19) to the form
x= τ3, y= τ4 + ω(τ),
1
where ω(τ) is ∞-flat at the origin. It is clear that using the change of variable y→y−ω(x
3 ),
we kill the «tail» ω(τ) and obtain required form (2.17). But it is necessary to check that
1
the function ω(x
3 ) is smooth at 0. More exactly, we need to prove that all the derivatives
1
of ω(x
3 ) tend to zero as x→0. The proof of this fact is trivial and left to the reader (hint:
use Hadamard’s lemma).
The obtained results can suggest that #n= 1 also for n>3, but it is wrong.
Exercise 20.
Prove that #4 = 2 and for any curve (2.13) with n= 4 there exists a smooth local change
of the variables x,y bringing this curve to one of the following normal forms:
x= τ4, y= τ5; x= τ4, y= τ5 + τ7 in a neighborhood of the origin.
Hint: This statement can be proved using the similar arguments as the previous.
We always used above C∞-smooth changes of coordinates. It is reasonable to ask: what’s
happened if we weaken this condition to a finite smoothness?
Exercise 21.
Prove that two normal forms from (2.21) are C1-smooth equivalent, but not C2-smooth
equivalent.
Solution: Establish C1-smooth equivalence in more general case: for any n there exists a
smooth local change of the variables x,ybringing curve (2.13) to the form x= τn, y= τn+1
.
To prove this statement for odd n it is convenient to use formula (2.13) with ϕ(τ) = 1 and
ψ(τ) = 1 + χ(τ), χ(0) = 0. Using Hadamard’s lemma n times, we get
χ(τ) = χ1τ +···+ χn−1τn−1 + τnχ(τ),
where χ(τ) is a smooth function. Hence
y= τn+1(1 + χ(τ)) = τn+1(1 + τnχ(τ)) + τn(χ1τ2 +···+ χn−1τn),
and the required C1-smooth change of coordinates is
y→
2
y−x(χ1x
n
n +···+ χn−1x
n )
1
1 + xχ(x
n )
.
(2.21)
21
The proof for even n is similar and left to the reader. Hint: use formula (2.13) with the
functions ϕ(τ) = 1 + χ(τ) and ψ(τ) = 1.
Suppose that there exists a C2-smooth local change of variables ξ= f(x,y), η= g(x,y)
thatturnsthesecondcurvefromformula(2.21)tothefirstone.ApplyingHadamard’slemma
to the functions f and g two times, we can represent this change of variables in the form
ξ= a1x+ a2y+ (a3 + ϕ3(x,y))x2 + (a4 + ϕ4(x,y))xy+ (a5 + ϕ5(x,y))y2
,
η= b1x+ b2y+ (b3 + ψ3(x,y))x2 + (b4 + ψ4(x,y))xy+ (b5 + ψ5(x,y))y2
,
where ai,bi are constants, and ϕi(x,y),ψi(x,y) are continuous functions vanishing at the
origin. Substituting the above expressions for ξ and η in the equality ξ5 = η4, which defines
the curve ξ= τ4
, η= τ5, and substituting x= τ4
, y= τ5 + τ7, we get the identity
(a1τ4 + a2(τ5 + τ7) + a3τ8 + o(τ8))5 = (b1τ4 + b2(τ5 + τ7) + b3τ8 + o(τ8))4
.
Comparing the coeﬃcients of the monomials of degrees ≤2 in the left and right hand sides
of the identity, we see that a1 = b1 = 0. Whence the Jacobian of the map (x,y)→(ξ,η) is
equal to zero, and the required C2-smooth change of coordinates does not exist.
We will not further investigate the classification of the singularities of plane curves. There
exist a lot of papers and books concerning this subject, for instance:
•V.I. Arnol’d. Simple Singularities of Curves. Proc. Steklov Institute of Mathematics,
vol. 226 (1999), pp. 20-28.
•J.W. Bruce, T. Gaﬀney. Simple singularities of maps (C,0)→(C2
,0). J. London Math.
Soc. (2), 26 (1982), pp. 464–474.
•J.W. Bruce, P.J. Giblin. Curves and Singularities. Cambridge University Press, 1984.
•C.T.C. Wall. Singular Points of Plane Curves. London Math. Soc. Student Texts 63.
•M. Zhitomirskii, Fully simple singularities of plane and space curves. Proc. London
Math. Soc. 96:3 (2008), pp. 792–812.
True,inthispapersandbookstheanalytic(butnotsmooth)classificationwasconsidered.
To my knowledge, Ck-smooth (with finite k>1) classification of the singularities of plane
curves is not studied yet. According to the cited paper by Bruce and Gaﬀney, in the analytic
classification #n= ∞for all n>4. On the other hand, C1-smooth changes of the variables
allow to bring the germ of each curve (2.13) to the from x= τn, y= τn+1 and even conjugate
curves with diﬀerent n. The diﬀerence between the Ck-smooth classifications with diﬀerent
k > 1 and n > 4 is not evident a priori Probably, this question is an interesting and not
trivial problem waiting for the solution.
22
3 Lecture 3. Singularities of Maps.
In the previous lecture we studied singularities of the integral curves of implicit diﬀerential
equations (this studying is based on the elementary facts form the Lecture 1). The next aim
is to study phase portraits (i.e., the families of the integral curves) of implicit diﬀerential
equations in neighborhoods of their singular points. This problem is considered in the next
lecture, now we give some necessary facts for the Singularity Theory.
3.1 Malgrange Preparation Theorem.
Let f(x) : Rn →Rn be a smooth map (as before, smooth means C∞) defined by n smooth
functions:
f(x) = (f1(x),...,fn(x)), x= (x1,...,xn), f(0) = 0. (3.1)
Our first aim is to define «multiplicity» of the germ f(x) at 0. Recall that in the Lecture 1
we defined multiplicity of germs f(x) : Rn →R as the dimension of the local algebra of the
gradient map (1.4). The similar construction is used for map (3.1).
LetAn = R[[x1,...,xn]] = thealgebraofformalseriesofthevariablesx1,...,xn.Consider
the ideal If ⊂An generated by the functions f1(x),...,fn(x) from (3.1). More exactly, the
idealIf ⊂An isgeneratedbytheformalseriescorrespondingtothefunctionsf1(x),...,fn(x).
Definition 1:
The factor-algebra Qf := An/If is called the «local algebra» of the map f(x) at the
point 0. The number µ = dim(An/If) is called the multiplicity of the map f(x) at 0 (here
«dim» means the dimension of the local algebra as a vector field over R).
In the case n = 1 we have two definitions of multiplicity of the map f(x) : R1 →R1
.
Namely, the «old» multiplicity defined in the Lecture 1 (now denote it by µ′), and the «new»
multiplicity µ defined above. It is not hard to see that µ= µ′+ 1. The reason is clear: µ′ is
defined through the gradient map of f, that is, the map f′(x) : R1 →R1. The diﬀerentiation
reduces the multiplicity by 1. That’s why we have µ′
= µ−1.
Definition 2:
Suppose µ < ∞, that is, Qf= An/If is a finite-dimensional local algebra. A system of
generators of Qf is a set of elements e1(x),...,eµ(x) of the algebra An which goes back into
a system of generators of the vector space Qf on factoring by the ideal If.
This means that any element g(x) ∈An can be represented in the form
g(x) = α1e1(x) +···+ αµeµ(x) + β1(x)f1(x) +···+ βn(x)fn(x) (3.2)
with appropriate constants αi ∈R and elements βi(x) ∈An.
By C∞[x1,...,xn] denote the algebra of smooth germs of the variables x1,...,xn at the
point0.PutAn = C∞[x1,...,xn] andrepeatallreasoningswhichweusedabovefordefinition
of the local algebra Qf := An/If, the multiplicity µ and the generators. Then we get the
similar definitions in two categories: formal series and smooth germs.
The pleasant and useful fact is that for µ<∞these notions (multiplicity and generators)
coincide. Further we deal with the case µ<∞, hence we can operate simultaneously in two
categories: An = R[[x1,...,xn]] and An = C∞[x1,...,xn]. The obtained results will be
similar.
Exercise 1.
Calculate the multiplicity at 0 of the maps f(x,y) : R2 →R2 given by the following
formulas:
23
f1
= x, f2
f1
= x, f2
f1
= xy, f2
= x2 + y2;
= xy;
= x2 + y2
.
Exercise 2.
Prove that if 0 is the regular point of the map f(x), that is, the Jacobian Jf(0) ̸= 0, then
µ= 1.
Solution: From the condition Jf(0) ̸= 0 it follows that the functions f1(x),...fn(x) are
local coordinates in a neighborhood of 0. Thus it is suﬃcient to prove this statement for the
identical map: fi(x) = xi. Using Hadamard’s lemma, we can represent any function g ∈An
in the form g= g(0)+x1g1(x)+···+xngn(x). Hence An/If (as a vector space) is isomorphic
to R, and µ= 1.
Now we can formulate the main result:
Malgrange Preparation Theorem. Let An = R[[x1,...,xn]] or An = C∞[x1,...,xn],
µ < ∞and e1(x),...,eµ(x) be generators of the corresponding local algebra Qf. Then any
element h(x) ∈An can be represented in the form
h(x) = a1(f(x))e1(x) +···+ aµ(f(x))eµ(x), ai(·) ∈An. (3.3)
This theorem is also called «Malgrange–Weierstrass Preparation Theorem». The proof in
the category of formal series (An = R[[x1,...,xn]]) is rather simple, it can be found in:
•V.I. Arnold, S.M. Gusein-Zade, A.N. Varchenko. Singularities of Diﬀerentiable Maps. –
Birkhauser, Boston, 1985, Vol.1, Monogr. Math. 82.
However in the smooth category (An = C∞[x1,...,xn]) the proof is much more diﬃcult, it
requires some advanced techniques, for instance, work with finitely generated modules and
Nakayama’s lemma. The proof in the smooth category can be found in:
•B. Malgrange. Ideals of diﬀerentiable functions. – Oxford University Press, Oxford,
1966.
•M. Golubitsky, V. Guillemin. Stable maps and their singularities. – Graduate Texts in
Mathematics, vol.14, Springer-Verlag, 1973.
•Th.Br¨ocker,L.Lander.DiﬀerentialbleGermsandCatastrophes.–CambridgeUniversity
Press, 1975.
Exercise 3.
What does Malgrange Preparation Theorem (MPT) give in the case µ= 1 (that is, f is
a local diﬀeomorphism)?
Solution: In the case µ = 1 the functions f1(x),...fn(x) are local coordinates in a
neighborhood of 0, and using Hadamard’s lemma, we can represent any function g ∈An in
the form g= g(0) + β1(x)f1(x) +···+ βn(x)fn(x) with appropriate βi(x) ∈An. Comparing
this representation with (3.2), we see that the function e1(x) = 1 is the generator of
the local algebra Qf (we can put e1(x) equal to any constant function except for zero).
Hence representation (3.3) reads h(x) = a1(f(x))e1(x) = a1(f(x)). This equality does not
contain any information: since f is a local diﬀeomorphism, we can take the new variable
y= f(x), then for any h ∈An the equality h(x) = a1(f(x)) holds true with the function
a1(y) = h(f−1(y)).
24
However MPT is a very powerful instrument when we deal with the germ of functions at
critical points (1 <µ<∞). It allows to get a lot of important results, some of them will be
described below.
Exercise 4.
Prove the Lemma 3 from the Lecture 1: any smooth function h(x,y1,...,yn−1) : Rn →R
can be represented in the form
h(x,y1,...,yn−1) = a1(x2,y1,...,yn−1) + xa2(x2,y1,...,yn−1), (3.4)
where a1 and a2 are smooth functions.
Solution: Denote y = (y1,...,yn−1) and consider the smooth map f(x,y) : Rn →Rn
defined by the following n functions:
f1(x,y) = y1, ..., fn−1(x,y) = yn−1, fn(x,y) = x2
. (3.5)
Applying representation (1.8) with n = 2 to the function g(x,y) from (3.2) and using
Hadamard’s lemma, we get
g(x,y) = g0(y) + xg1(y) + x2g2(x,y) =
= g0(0) +
n−1
i=1
g0i(x,y)yi + x g1(0) +
n−1
i=1
g1i(x,y)yi + x2g2(x,y) =
= g0(0) + xg1(0) +
n−1
i=1
βi(x,y)fi(x,y) + g2(x,y)fn(x,y),
that is, representation (3.2) with µ = 2 and e1(x,y) = 1, e2(x,y) = x. Hence the local
algebra Qf of map (3.5) is generated by the germs 1 and x. Then representation (3.3) reads
h(x,y) = a1(f(x,y)) + xa2(f(x,y)). This is required equality (3.4).
Exercise 5.
Prove the generalization of formula (3.4): for any integer number p ≥ 2 any smooth
function h(x,y1,...,yn−1) : Rn →R can be represented in the form
h(x,y) = a1(xp,y) + xa2(xp,y) +···+ xp−1ap−1(xp,y), (3.6)
where ai are smooth functions, y= (y1,...,yn−1).
Hint: consider the map f(x,y) : Rn →Rn defined by (3.5) where x2 is replaced with xp
.
25
Exercise 6.
Apply MPT to the smooth map f(x,y) : R2 →R2 defined by the functions:
f1(x,y) = x3 + xy, f2(x,y) = y. (3.7)
Solution: Prove that µ = 3 and the local algebra Qf of map (3.7) is generated by the
functions e1(x,y) = 1, e2(x,y) = x, e3(x,y) = x2. Indeed, using representation (1.8) and
Hadamard’s lemma, we can represent any function g(x,y) ∈A2 in the form
g(x,y) = g(0) + α1x+ α2x2 + yβ1(x,y) + x3β2(x,y), β1,2(x,y) ∈A2, α1,2 ∈R.
Clearly, g(x,y) = g(0) + α1x+ α2x2 + yβ1(x,y) + (x3 + xy)β2(x,y), where β1 = β1−xβ2.
Thus we have representation (3.2) with µ= 3 and e1 = 1, e2 = x, e3 = x2. Then (3.3) gives
h(x,y) = a1(f1,y) + xa2(f1,y) + x2a3(f1,y), (3.8)
where f1(x,y) is taken from (3.7).
Exercise 7.
Establish formula (3.8) for the map f(x,y) : R2 →R2 defined by the functions:
f1(x,y) = ϕ(x,y)(x3 + xy), f2(x,y) = y, where ϕ(x,y) is a smooth non-vanishing function.
Hint: The proof is similar to the previous one.
(3.9)
3.2 Generic singularities of mappings R2 →R2
.
In this part of the lecture we study generic singularities of mappings R2 →R2. Since we
work with germs, i.e., do everything in suﬃciently small neighborhoods of singular points,
this is equivalent to studying of generic singularities of mappings M2 →N2, where M2 and
N2 are real smooth 2-manifolds.15
Consider the map f(x,y) : R2 →R2 given by the smooth functions f1(x,y) and f2(x,y).
Our aim is to simplify the functions f1,f2 using smooth changes of variables in the preimage
(M2) and the image (N2). This means that if (x,y) are local coordinates on M2 and (z,w)
are local coordinates on N2, we can use two independent changes of the variables:
ϕ: (x,y)→(x,y) and ψ: (z,w)→(z,w). (3.10)
The map has the form z = f1(x,y), w = f2(x,y) in the old coordinates and the form
z = g1(x,y), w= g2(x,y) in the new coordinates.
It is possible to write this in the following commutative diagram:
f=(f1,f2)
M2
−−−−−−→N2
(x,y)
(z,w)
 ϕ
 ψ
(3.11)
g=(g1,g2)
M2
−−−−−→ N2
(b
x,b
y)
(b
z,b
w)
The word «commutative» means that composition of the left and lower arrows coincides
with composition of the upper and rights arrows, i.e., g◦ϕ= ψ◦f, or equivalently,
g= ψ◦f ◦ϕ−1
. (3.12)
15I hope the reader see the relationship with implicit diﬀerential equations: the projection π from the surface F to the plane.
26
The change of coordinates ϕ: (x,y)→(x,y) is called «right», and the change of coordinates
ψ : (z,w)→(z,w) is called «left» according to formula (3.12) in spite in diagram (3.11) it
is vice versa.
Definition 3: The functions f and g at the point 0 are called «right-left equivalent» or
shortly «RL-equivalent» if they are connected with relation (3.12) with diﬀeomorphisms ϕ
and ψ. If we use only right change of variables ϕ (i.e., ψ= id ), we get «R-equivalence»; if
we use only left change of variables ψ (i.e., ϕ= id ), we get «L-equivalence».
Clearly, we can define all these types of equivalence for maps f : Mm →Nn with any
dimensions mand n. Besides, we already have dealt with some partial cases of these notions.
Example 1:
TheMorseLemmastatesthateachsmoothfunctionf : Mm →N1 atanynon-degenerated
critical point is R-equivalent to its own quadratic part. Tougeron’s Theorem states that each
smooth function f : Mm →N1 at any critical point with µ < ∞(here multiplicity µ is
defined as in the Lecture 1) is R-equivalent to its own Taylor polynomial of degree µ+ 1.
Example 2:
In the Exercises 18–20 from Lecture 2 we deal with RL-equivalence of maps f : R1 →R2
(we change the coordinate τ in the preimage and the coordinates x,y in the image).
Example 3:
Any smooth map f : Mm →Nn which has the constant rang k(rang of a map is the rang
of its derivative, i.e., Jacobi matrix) in a neighborhood of 0 is RL-equivalent to the map
fi(x1,...,xm) = xi (i≤k), fi(x1,...,xm) = 0 (i>k).
The proof of this fact is left to the reader or can be found in: V.A. Zorich. Mathematical
Analysis. In particular, in the case n= m= k the diﬀeomorphism f is RL-equivalent to id.
Moreover, any diﬀeomorphism is R-equivalent to id and also L-equivalent to id.
Consider the map f(x,y) : M2 →N2 given by the functions
z = f1(x,y), w= f2(x,y), f1(0) = f2(0) = 0, (3.13)
in a neighborhood of the origin. The Jacobi matrix of this map is
Af=  
f1
x f1
y
f2
x f2
y
  (3.14)
The singular points of this map are defined by the condition |Af|= 0, i.e., rg Af = 1 or
rg Af = 0. The set {(x,y) : rg Af(x,y) = 1}has codimension 1 and generically is a curve on
the (x,y)-plane. The set {(x,y) : rg Af(x,y) = 0}has codimension 4, hence in generic case
it is empty.
Suppose the set of the singular points is {(x,y) : rg Af(x,y) = 1}. Then map (3.13) is
R-equivalent to
z = F(x,y), w= y, F(0) = 0, (3.15)
where F(x,y) is a smooth function (the proof is trivial and left to the reader). The singular
point of map (3.15) are given by the equation
|Af|=
Fx Fy
0 1
= 0 ⇐⇒ Fx(x,y) = 0,
which defines a regular curve if |Fxx|+ |Fxy|̸= 0.
27
Since the both sets {(x,y) : Fx = Fxx = Fxy = 0}and {(x,y) : Fx = Fxx = Fxxx = 0}
have codimension 3, there are only two generic cases:
•Fx(0) = 0, Fxx(0) ̸= 0.
•Fx(0) = 0, Fxx(0) = 0, Fxy(0) ̸= 0, Fxxx(0) ̸= 0.
These singularities are called «fold» and «pleat», respectively. Sometimes they are called
«Whitney fold» and «Whitney pleat».
Notice that to define fold and pleat of map (3.13), we used the special coordinates
(such that the second function f2(x,y) coincides with one of the coordinates x,y in the
preimage M2). However it is possible to define fold and pleat using only invariant notions
(which do not depend on the choose of coordinates).
There are two main invariant objects connected with the singularity of map f satisfying
the condition rg df(0) = 1. The first object is the curve S defined by the equation |Af|= 0,
this curves that consists of the singular points of the map. The second object is the direction
field χ= ker df defined at the points of S. The field χ is defined only on the curve S: at all
points / ∈S the diﬀerential df is non-degenerated, and ker dx= 0. Choosing the coordinates
in M2 and N2, we can express the map df : TM2 →TN2 through the matrix Af, then the
field χ= ker Af.
Example 4:
The curve S and the field χ for maps (3.15) with F= x2 and F= x3 + xy are depicted
on the following picture:
Exercise 8.
Prove that fold and pleat can be defined by the following conditions:
•S is regular (∇S ̸= 0) and χ is transversal to S at 0.
•S is regular, χ is tangent to S at 0, and the tangency has the first order.
Hint:Sincetheconditionsoftheseconddefinitionaregeometricallyinvariant,itissuﬃcient
to prove the equivalence of the first and second definitions for map (3.15)
Now we can prove the main result of this lecture: Whitney Theorem about the normal
forms of maps in neighborhoods of fold and pleat.
Whitney Theorem. In neighborhoods of fold and pleat any map f(x,y) : M2 →N2 is
RL-equivalent to the following normal forms:
•z = x2, w= y,
•z = x3 + xy, w= y,
28
respectively.
It is suﬃcient to prove this statement for map (3.15).
Proof for Fold. By the condition Fxx(0) ̸= 0, the curve S : Fx(x,y) = 0 has the form
x= ϕ(y) with a smooth function ϕ. The change of variable x→x−ϕ(y) turns this curve to
the axis x= 0, and in the new coordinates the function Fx(x,y) vanishes on the line x= 0.
According to Exercise 6 form Lecture 1, we have the representation
F(x,y) = F0(y) + x2ϕ(x,y), where F0(y) = F(0,y),
with a smooth function ϕ(x,y). The condition Fxx(0) ̸= 0 implies ϕ(0) ̸= 0. Moreover, we
may assume that ϕ(0) >0, since the change of variable z →−z changes the sign of ϕ.
Then the change of variable x→x ϕ(x,y) gives F(x,y) = F0(y) + x2, i.e., the map has
the form
z = F0(y) + x2, w= y.
Finally, using the change of variable z →z−F0(w), we get the formula
Fold : z = x2, w= y (3.16)
Proof for Pleat.
Step One. Prove that map (3.15) with the function F(x,y) satisfying the conditions
Fx(0) = 0, Fxx(0) = 0, Fxy(0) ̸= 0, Fxxx(0) ̸= 0,
is RL-equivalent to the map (3.15) with F= ϕ(x,y)(x3 + xy), where ϕis a smooth function,
ϕ(0) ̸= 0. According to Exercise 5 form Lecture 1, we can write the function F using
representation (1.8) with n= 1:
F(x,y) = F0(y) + xg(x,y), where F0(y) = F(0,y),
where
g(0) = 0, gx(0) = 0, gy(0) ̸= 0, gxx(0) ̸= 0.
Then after the change of variable z →z−F0(w) we get F0(y) ≡0, i.e., F= xg(x,y).
Apply the Division Theorem to the function g(x,y). Since the multiplicity of g(x,y) by
the variable x is µ= 1, we have
g(x,y) = ϕ(x,y) (x2 + 2a(y)x+ b(y)), ϕ(0) ̸= 0. (3.17)
The change of variable x →x+ a(y) kills the middle term in (3.17), i.e., a(y) ≡0. The
conditions g(0) = 0, gy(0) ̸= 0 imply b(0) = 0, b′(0) ̸= 0. Hence we can make the «right»
change of variables y→b(y) and the «left» change of variables w→b(w). This yields
z = F(x,y), w= y, (3.18)
where F(x,y) = xϕ(x,y)(x2 + y) = ϕ(x,y)(x3 + xy), ϕ(0) ̸= 0.
Step Two: consider map (3.18). According to the results obtained in Exercises 6 and 7
(from Lecture 3), any smooth function h(x,y) can be represented in the form
h(x,y) = a1(F,y) + xa2(F,y) + x2a3(F,y), where F= ϕ(x,y)(x3 + xy) (3.19)
with appropriate smooth functions ai of two variables. Applying representation (3.19) to the
function h(x,y) = x3 and changing a2 →−a2, a3 →3a3, we get
x3
= a1(F,y)−xa2(F,y) + 3x2a3(F,y), where F= ϕ(x,y)(x3 + xy). (3.20)
29
Representation (3.20) has the form
(x−a(F,y))3 + b(F,y)(x−a(F,y)) = c(F,y), where F= ϕ(x,y)(x3 + xy),
and a= a3, b= a2−3a2
, c= a1−ab−a3. It is not hard to check that the following pair of
right and left changes of variables
(x,y)→(x,y) : x= x−a(F(x,y),y), y= b(F(x,y),y)
(z,w)→(z,w) : x= c(z,w), w= b(z,w)
brings the map to the form
Pleat : z = x3 + xy, w= y (3.21)
Remark. The above theorem was initially proved in the paper:
•H. Whitney. On singularities of mappings of Euclidean spaces. I. Mappings of the plane
into the plane. – Ann. of Math., 62 (1955), pp. 374–410.
In his proof Whitney used more elementary techniques (Malgrange Preparation Theorem
was proved later on), but his proof is much longer.
Finally, it is very useful to understand how do maps (3.16) and (3.21) look like. Since in
the both cases one coordinate in the image (w) coincides with one coordinate in the preimage
(y), both maps can be realized as the projection π from a smooth surface F in the (x,y,z)-
space to the (y,z)-plane along the x-axis. The set of the singular (critical) points S ⊂F is
said to be the criminant, and its projection π(S) is said to be the discriminant curve.
In the case (3.16) this surface is the parabolic cylinder z = x2. The projection π is a
double covering of the semi-plane (y,z >0), with branching at z = 0. The criminant is the
y-axis in the (x,y,z)-space, the discriminant curve is the y-axis on the (y,z)-plane.
In the case (3.21) this surface is the graph of the function z = x3 + xy. The criminant
is the parabola 3x2 + y = 0 on the surface F . The discriminant curve is the semi-cubic
parabola
y=−3x2, z=−2x3
.
on the (y,z)-plane. The cusp occurs at the point where the curve Sis tangent to the direction
field χ= x-direction.
Exercise 9.
Draw the surface F , the criminant and the discriminant curve for map (3.21). How many
points does the preimage π−1(y,z) contain? How is this picture connected with the number
of real roots of the cubic polynomial p(x) = x3 + ax+ b with real coeﬃcients a,b?
Exercise 10. Why the singularities of the maps:
1) z = x3, w= y,
2) z = x4, w= y,
are not generic?
Hint: for the first map consider the perturbation z = x3 + εx, w= y.
30
4 Lecture 4. Implicit Diﬀerential Equations: Normal Forms and
Phase Portraits.
In this lecture, we continue to study Implicit Diﬀerential Equations from the Singularity
Theory viewpoint. We have already studied the singularities of the individual integral curves
(lecture 2), now the aim is to get the normal forms of such equations and/or their phase
portraits in neighborhoods of the singular points.
Recall that the singular points of the Implicit Diﬀerential Equation
dy
F(x,y,p) = 0, where p=
dx, (4.1)
are the points of the surface F : F = 0 such that Fp = 0, i.e., critical points of the projection
π: F →(x,y). Let µ<∞be the multiplicity of F by the variable pat the singular point T0:
∂F
∂µF
∂µ+1F
∂p(T0) = 0, ...,
∂pµ (T0) = 0,
∂pµ+1 (T0) ̸= 0.
As we saw in the previous lecture, in generic case the projection π has only two types of
singularities (= critical points). The first type is the Fold, it is defined by the condition
Fpp(T0) ̸= 0 ⇔ µ= 1. (4.2)
The second type is the Pleat, it is defined by two conditions:
Fpp(T0) = 0, Fppp(T0) ̸= 0 ⇔ µ= 2 and Fxp(T0) ̸= 0 or Fyp(T0) ̸= 0. (4.3)
For generic equation (4.1) the criminant K consists of the points satisfying condition (4.2)
except for the isolated points satisfying condition (4.3).
Moreover,forgenericequation(4.1)theintersectionofthecriminantK andtheinflection
curve L consists of the isolated points that satisfy condition (4.2). The subset of the surface
F defined by the equations Fp = 0, Fpp = 0, G= 0 has codimension 3; hence in generic case
it is empty.
Thus we will consider three types of the singular points:
• Fpp(T0) ̸= 0 and G(T0) ̸= 0.
• Fpp(T0) ̸= 0 and G(T0) = 0.
• condition (4.3) and G(T0) ̸= 0.
In the first and second cases π: F →(x,y) is fold, and in the third case π is pleat.
4.1 «Regular» singular points
The singular points that satisfy the conditions
Fpp(T0) ̸= 0, G(T0) ̸= 0
are called «regular».16 There exist another definition: the singular points are said to be
«regular» if the map (x,y,p)→(F,Fp) has maximal rang (=2) and the criminant is not
tangent to the contact plane The second definition is used in the books:
16The combination of the words «regular singular points» seems strange. However it can be explained. This terminology
belongs to V.I. Arnold and initially was in Russian; English translation is a calque from Russian. In Russian there are several
words that can be translated as «singular» in English, that’s why the initial Russian term does not sound like «hot ice».
31
•V.I. Arnold. Geometrical methods in the theory of ordinary diﬀerential equations. –
Springer-Verlag 1988.
•V.I. Arnold, Yu.S. Il’yashenko. Ordinary diﬀerential equations. In Dynamical systems I,
Encyclopaedia Math. Sci., vol.1.
•A.A. Davydov. Qualitative Theory Of Control Systems. – Transl. Math. Monogr. 141,
AMS, Providence, Rhode Island, 1994.
Exercise 1.
Check the equivalence on these definitions.
Regular singular points are «most typical» singular points in the following sense. The
criminant of a generic Implicit Diﬀerential Equation consists of the regular singular points
except for isolated points.
Example 1. The equation p2 + x = 0 describes the characteristic curves of the partial
diﬀerential equation uxx+ xuyy = 0, which is called «Tricomi equation» (sometimes «Euler–
Tricomi equation»). Tricomi equation is the simplest example of so-called «mixed» PDEs,
i.e., linear PDEs of the second order that have diﬀerent types at diﬀerent points.17
Clearly, all singular points of the equation p2 + x= 0 are regular. The discriminant curve
x = 0 separates the (x,y)-plane into two parts. Tricomi equation is hyperbolic in the half
plane x < 0 and elliptic in the half plane x > 0. The characteristic curves are semi-cubic
parabolas, which belong to the hyperbolic semi-plane and have cusps at x= 0.
Definition: Two Implicit Diﬀerential Equations are called «equivalent» if there exists
a change of variables (x,y) that transforms the family of the integral curves of the first
IDE into the family of the integral curves of the second IDE. More exactly, IDEs are called
«topologically equivalent» if shuch change of variables f : R2 →R2 is a homeomorphism,
«smoothly equivalent» if f is a smooth diﬀeomorphism, «analytically equivalent» if f is
an analytical diﬀeomorphism. In both cases the diﬀeomorphism f is called «conjugating
diﬀeomorphism».
Example 2. The Implicit Diﬀerential Equation p4
−1 = 0 is smoothly (and analytically)
equivalent to p2
−1 = 0. The conjugating diﬀeomorphism f is identical. Indeed, p4
−1 =
(p2
−1)(p2 + 1). Hence the equations p4
−1 = 0 and p2
−1 = 0 have the same family of the
integral curves, and not necessary to use any change of varibles!
Example 3. The Implicit Diﬀerential Equation p2y = 1 is smoothly (and analytically)
equivalent to p2
= x. The conjugating diﬀeomorphism f is interchanging x and y. Indeed,
the interchanging x and y turns p2
= x to p−2
= y, that is, p2y= 1.
Theorem1.In a neighborhood of any regular singular point T0, equation (4.1) is smoothly
equivalent to p2
= x.
The normal form p2
= x is called «Cibrario normal form» (this name was suggested
by V.I. Arnold) after Italian female mathematician Maria Cibrario (1905–1992). She has
established this normal form when she studied the characteristics of linear second-order
mixed PDEs with analytic coeﬃcients:
•M. Cibrario. Sulla reduzione a forma canonica delle equazioni lineari alle derivative
parzialy di secondo ordine di tipo misto. – Rend. Lombardo 65 (1932), pp. 889–906.
17Mixed PDEs became important in describing an object moving at supersonic speed (in the middle of XX century). Of course
there were no supersonic aircraft in the time when Francesco Tricomi studied his famous equation (1923), but this equation
was to play a major role in later studies of supersonic flight (another important mixed PDE is Chaplygin’s equation).
32
Recall that IDEs which describe characteristics of linear second-order mixed PDEs have the
form(4.1),wherethefunctionF isasecond-orderpolynomialinpwithcoeﬃcientsdepending
on x,y. Later on, this normal form was obtained in general case and in the smooth and
analytic categories simultaneously. This proof can be found in the famous textbook:
•V.I. Arnold. Geometrical methods in the theory of ordinary diﬀerential equations. –
Springer-Verlag, 1988.
We follow the proof from this book, with some unsignificant modifications.
Proof.
Step One. Without loss of generality we may assume that the point T0 is the origin of J1
.
Choosing appropriate local coordinates in a neighborhood of the origin on the (x,y)-plane,
one can bring the criminant of equation (4.1) to the line x= p= 0 (the y-axis).
Indeed, equation (4.1) defines the direction field χ on the discriminant curve D that at
each point (x,y) ∈D the direction dy : dx corresponds to the unique root p= p(x,y)
of the equation F(x,y,p) = 0 with respect to p. Let’s show that the direction field χ is
transversal to the discriminant curve D. Clearly, it is suﬃcient to prove that the criminant
K : F= Fp = 0 is transversal to the contact plane pdx−dy= 0. This is equivalent to
∆ =
Fx Fy Fp
Fxp Fyp Fpp
p−1 0
̸= 0.
At point of the criminant we have Fp = 0, hence ∆ = (Fx + pFy)Fpp = FppG̸= 0.
Since the direction field χ is transversal to the discriminant curve D, there exist local
coordinates(x,y) ontheplanesuchthatthediscriminantcurveD isx= 0 andthecoordinate
lines y= const intersect x= 0 with tangent directions χ, see the figure:
Further we will use the same letters x,y for the new coordinates x,y, i.e., suppose that K
is the y-axis in the initial coordinates.
Step Two. Using the Division Theorem, we can represent the function F(x,y,p) in the
form F(x,y,p) = ϕ(x,y,p)(p2 + 2a(x,y)p + b(x,y)), where a,b,ϕ are smooth fucntions,
a(0) = b(0) = 0 and ϕ(0) ̸= 0. Hence in a neighborhood of the origin equation (4.1) is
equivalent to
dy
p2
−2a(x,y)p+ b(x,y) = 0, p=
dx. (4.4)
The criminant of equation (4.4) is the y-axis, hence a(0,y) = b(0,y) = 0 (∀y). By the Lemma
1 (from Lecture 1) we have the representations a(x,y) = xα(x,y) and b(x,y) = xβ(x,y) with
smooth functions α,β. The condition G ̸= 0 for equation (4.4) implies β(0) ̸= 0. Without
loss of generality we may assume β(0) <0, otherwise x→−x.
33
Consider equation (4.4) as a square equation by p, then we get the solution
p= a±√a2
−b= xα± x(xα2
−β) = xα±√xγ, where γ= xα2
−β.
In a neighborhood of the origin, the function γ(x,y) >0, and the above solution pis real in
the semi-plane x≥0. Using the change of variable x= ξ2, we get
p= ξ2α(ξ2,y) ±ξ γ(ξ2,y). (4.5)
Of course, the change of variables (x,t)→(ξ,y) is not a diﬀeomorphism and even not one-
to-one map of a neighborhood of the origin of the (x,y)-plane. However it is one-to-one map
of the half plane x≥0, which contains all solutions of equation (4.4). This justifies using of
the change of variable x= ξ2
.
Step Three. The variable ξ takes both positive and negative values, hence we can put
in formula (4.5) the sign «+» instead of «±». Since p= dy/dx= dy/(2ξdξ), equality (4.5)
gives the following diﬀerential equation for the variables ξ,y:
dy
dξ = 2ξ(ξ2α(ξ2,y) + ξ γ(ξ2,y)) = ξ2ω(ξ2,y), (4.6)
where ω= 2(ξα+ √γ) is a smooth function and ω(0) >0.
The integral curves of equation (4.6) intersect the y-axis (on the (ξ,y)-plane) with the
horizontal tangent directions (= parallel to the ξ-axis). Moreover, form ω(0) ̸= 0 it follows
that at the points with ξ = 0 the integral curves have the second order tangency with
corresponding coordinate lines y = const (like cubic parabolas). Hence equation (4.6) has
the first integral
I(ξ,y) = y−ξ3f(ξ,y), f(0) ̸= 0,
wheref isasmoothfunction.UsingLemma3(fromLecture1),wecanrepresentthefunction
f(ξ,y) = f1(ξ2,y) + ξf2(ξ2,y) with smooth sunctions f1,2. Then
I(ξ,y) = y−ξ3f1(ξ2,y)−ξ4f2(ξ2,y), f1(0) ̸= 0. (4.7)
Step Four. The change of variables (ξ,y)→(Ξ,Y) by the formula
Ξ = ξf1/3
1 (ξ2,y), Y= y−ξ4f2(ξ2,y),
transforms the above first integral to I= Y−Ξ3. Recall that x = ξ2 and introduce the
variable X = Ξ2, that is Ξ = ±√X. The change of variables (x,y)→(X,Y) by the formula
X= xf2/3
1 (x,y), Y= y−x2f2(x,y), (4.8)
transforms the equation Y−Ξ3 = c into Y ±X3/2
= c.
Hence the change of variables (4.8) transforms equation (4.1) into an implicit diﬀerential
equation posessing the family of the integral curves Y ±X3/2
= c. Using an appropriate
scaling of X or Y, it can be brought to the form Y= ±2
3 X3/2 + c. The equation possessing
the last family is
dY
P2
= X, where P=
dX.
This completes the proof.
34
Comments.
Remark that Cibrario normal form coincides with the normal form (Whitney fold) of the
projection π: F →(x,y). Theorem 1 claims that there exist local coordinates on the (x,y)-
plane such that given IDE is equivalent to p2
= x. The variables (p,y) are local coordinates
on the surface F of IDE p2
= x, and the projection π : (p,y)→(x,y) has the normal form
of the Whitney fold. However Theorem 1 and Whitney Theorem are diﬀerent statements.
Indeed, the Whitney Theorem deals with maps f : M →N, where M and N are two
diﬀerent manifolds with independent local coordinates: say, (x,y) on M and (z,w) on N.
The map f is RL-equivalent to g if there exists a pair of local diﬀeomorphisms ϕ: (x,y)→
(x,y) and ψ : (z,w)→(z,w) that in the new coordinates (with hats) the map f coincides
with the map g. In the case of Theorem 1 we also deal with map π : M → N, where
M= F and N=(x,y)-plane, but the local coordinates on the manifolds M and N are not
independent. Indeed, any change of the variables x,y denerates a change of the variable p,
since p= dy/dx.
18
4.2 «Pleated» singular points
Now consider the singular points that satisfy the conditions (4.3) and G(T0) ̸= 0. Without
loss of generality assume that T0 = 0.
Exercise 2. Prove that in a neighborhood of the pleated singular point 0, equation (4.1)
is smoothly equivalent to
dy
ph(y,p) = x, where p=
dx, (4.9)
where h(y,p) is a smooth function such that h(0) = hp(0) = 0, hpp(0) ̸= 0, hy(0) ̸= 0.
Hint: From G(0) ̸= 0 it follows that Fx(0) ̸= 0. Hence equation (4.1) is locally equivalent
to x= f(y,p) (Implicit Functions Theorem). The smooth function f(y,p) can be represented
in the form f(y,p) = g(y) + ph(y,p) with smooth g and h (Exercise 5 from Lecture 1). To
kill the term g(y), consider the change of variable x→x−g(y).
As it was remarked above, in the case when singularity of the projection π is a fold,
Theorem 1 cannot be derived from the Whitney Theorem, but the normal forms in both
theorems are the same (and very simple). However in the case when singularity of π is a
pleat, the generic IDE is not smoothly (and even topologically) equivalent to p3 + py= x.
Moreover, the smooth classification of pleated singular points has functional invariants, see:
•A.A. Davydov. Normal form of a diﬀerential equation, not solvable for the derivative,
in a neighborhood of a singular point. – Functional Anal. Appl. 19:2 (1985), pp. 81–89.
J.W. Bruce suggested a construction19 that gives a clear geometric description of the
phase portrait in a neighborhood of pleated singular points. This construction is based on
the special surface which is called «swallow tail».
This surface can be defined as follows. Consider the polynomials P(t) = t4 + at2 + bt+ c
of the real variable t with the real coeﬃcients a,b,c. Then «swallow tail» is a surface in the
(a,b,c)-space defined by the condition that P(t) has a multiple root, see the figure below.20
18It is similar to the well-known situation in Linear Algebra. Let A : L1 →L2 be an invertible linear operator, L1 and L2
are vector spaces of the same dimension. It is possible to bring Ato id using appropriate linear changes of variables in L1 and
L2, that is, ∃C1, ∃C2: C1AC−1
2 = id . However if we use the same linear change of variables in both spaces (for example, if
C1 = C2), one can bring A only to the Jordan normal form, that is, ∃C: CAC−1 = J, where J ̸= id if A̸= id.
19J.W. Bruce. A note on first-order diﬀerential equations of degree greater than one and wavefront evolution. – Bull. London
Math. Soc., 16 (1984).
20In 1983, spanish painter Salvador Dali created the picture which is called «Swallow Tail» (in fact, this painting contains
not the whole surface, but its section). This work became his last painting.
35
Exercise 3. Prove that the swallow tail divides the (a,b,c)-space into 3 regions which
correspond to the numbers of the real roots of P(t). Find the number of the roots at diﬀerent
points of the space. Write the swallow tail in the parametric form, i.e., as the image of a
smooth map R2 →R3
.
Exercise 4. Consider the similar construction for the polynomials P(t) = t3 +at2 +bt+c
of the real variable twith the real coeﬃcients a,b,c. Describe the surface in the (a,b,c)-space
defined by the condition that P(t) has a multiple root.
J.W. Bruce showed that the phase portrait of IDE (4.9) near the origin can be obtained
from the family of sections of the swallow tail constructed above in the (a,b,c)-space by
planes a = const using an appropriate submersion (a,b,c)→(x,y). He showed that the
phase portraits of such IDEs are essentially diﬀerent for two types of pleated points, which
are called «elliptic» and «hyperbolic» (see the figure above) and correspond to the cases
hy(0) > 0 and hy(0) < 0, respectively. Bruce conjectured that the smooth classification of
IDEs at pleated singular points has functional invariants. Later on, Davydov proved it even
for the topological classification, see the paper cited above.
4.3 «Folded» singular points
Finally, consider the singular points that satisfy the conditions Fpp(T0) ̸= 0 and G(T0) = 0.
At such points the projection π : F →(x,y) is fold, and the lifted vector field⃗
V vanishes.
There are three generic types of singular point of a vector field on a two-dimensional surface:
saddle, node and focus.
The point T0 is said to be «well-folded» if three additional genericity conditions hold true:
T0 is saddle or node or focus of the lifted field⃗
V, ratio of the eigenvalues λ1,2 of the linear
part of⃗
V at T0 is diﬀerent from ±1, and the eigenvectors are not tangent to the criminant
and to the p-direction.
Remark. Recall that the lifted field⃗
V is given by the formula
˙
x= Fp,˙
y= pFp,˙
p= G, where G:=−(Fx + pFy). (4.10)
Notice that the above formula defines a vector field not only on the surface F , but in whole
(x,y,p)-space,21 i.e., for the vector field on F one of the coordinates x,y,p is superfluous.
Computing eigenvalues of the matrix
A=  Fxp Fyp Fpp
pFxp pFyp Fp + pFpp
Gx Gy Gp
 (T0) =  Fxp Fyp Fpp
pFxp pFyp pFpp
Gx Gy Gp
 (T0),
21This circumstance allows to use the same construction (lifting) for studying IDEs with non-regular surface F (for example,
F can be a cone).
36
we get three values: λ1,λ2,0. The linear part of the vector field⃗
V obtained by restriction
of (4.10) to F , has the eigenvalues λ1,2 (generally speaking, one or even both of them can
be also equal to zero, but it is not the generic case). This statement follows from the fact
that F is the first integral of field (4.10).
Exercise 5. Let⃗
V be an arbitrary smooth vector field in n-dimensional phase space with
the coordinates x = (x1,...,xn), and⃗
V(x∗) = 0. By (λ1,...λn) denote the eigenvalues of
the linear part of⃗
V at x∗ (of course, this set may contain the equal values). Briefly, we say
that (λ1,...λn) is the spectrum of⃗
V at x∗.
Suppose that F is a smooth invariant hypersurface of the field⃗
V, and consider the
restriction⃗
V F . Prove that the spectrum of⃗
V F at x∗ can be obtained from (λ1,...λn)
after deleting one eigenvalue λi. Prove that this eigenvalue λi = 0 if the hypersurface F has
the form F = 0, where F is a regular first integral of⃗
V («regular» means ∇F ̸= 0).
A.A. Davydov obtained a list of smooth normal forms of IDE (4.1) at well-folded singular
points that satisfy the additional «linearizability condition»: in a neighborhood of given
point, the lifted vector field⃗
V on F is smoothly equivalent to its linear part.22 I stress that
here (and below) the lifted vector field⃗
V means the field in the surface F.
The suﬃcient condition for linearizability can be expressed through the eigenvalues λ1,2
of the lifted vector field⃗
V at T0. Namely, linearizability condition holds true if there are no
relations
λi = n1λ1 + n2λ2, n1,2 ∈Z+, n1 + n2 ≥2, i∈{1,2}. (4.11)
The relations (4.11) are called «resonances» between the eigenvalues λ1,2. In general,
presence of the resonance is an obstacle for the linearizability of a vector field. There is the
following result (which is a partial case of more general Sternberg–Chen Theorem): if there
are no resonances (4.11) then the vector field⃗
V is locally smoothly equivalent to its linear
part. This statement is valid for vector fields in the phase space of any finite dimension.
Exercise 6.
Find the resonances in the following cases:
1. λ1 : λ2 ∈N,
2. nλ1 + mλ2 = 0, where n,m∈N,
3. one of the eigenvalues λ1,2 is zero.
A. Davydov proved that in a neighborhood of any well-folded singular point T0 safisfying
the linearizability condition, equation (4.1) is smoothly equivalent to
(p+ αx)2
= y, where α<0 or 0 <α<1/8 or α>1/8. (4.12)
Three intervals for the parameter α in normal form (4.12) correspond to three types of the
lifted field⃗
V on the surface F : saddle, node, focus. The proof can be found in:
•A.A. Davydov. Normal form of a diﬀerential equation, not solvable for the derivative,
in a neighborhood of a singular point. – Functional Anal. Appl. 19:2 (1985), pp. 81–89.
•A.A. Davydov. Qualitative Theory of Control Systems, Math. Monogr., 141, Amer.
Math. Soc., Providence, Rhode Island (1994).
The phase portraits of equation (4.1) at such singular points are obtained after projection
of the saddle, node, focus of the lifted vector field from the surface F to the (x,y)-plane.
They are called «folded saddle», «folded node», «folded focus», respectively:
22Two vector fields are called «smoothly equivalent» if there exists a smooth diﬀeomorphism of the phase space (= change
of the variables) that turns the first vector field into the second one.
37
In fact, the phase portraits of folded saddle, folded node, folded focus were firstly obtained
by Poincar´e in his third «M´emoire sur les courbes d´efinies par les ´equations diﬀ´erentielles»
(1885). Later on, such singularities were considered by several authors before A.A. Davydov.
It is interesting to remark that folded saddle, folded node, folded focus occurred in a physical
work (1971) devoted to studying the conversion of electromagnetic waves into plasma waves
in an anisotropic plasma with two-dimensional inhomogeneity.23
In 1975 L. Dara formulated the conjecture about normal form (4.12) of equation (4.1)
in a neighborhoods of folded saddles, folded nodes, folded foci, but he didn’t prove this
statement.24 The proof was obtained by A. Davydov in 1985.
Later on, A. Davydov obtained normal forms (more complex that (4.12)) for well-folded
singular points without the linearizability condition (with resonances) and even in much
more degenerated case when one of the eigenvalues λ1,2 is zero.
23The interested reader is referred to the original paper: A.D. Piliya, V.I. Fedorov. «Singularities of electromagnetic wave
field in a cold plasma with two-dimensional inhomogeneity». – ZhETF, 60, N1 (1971). The similar text can be found in the
book: A.G. Litvak (ed.). «High-frequency plasma heating». – American Institute of Physics (1992), Chapter 6.
24More exactly, L. Dara suggested another normal form, which is equivalent to (4.12); see: Lak Dara. Singularit´es g´en´erique
des ´equations diﬀ´erentielles multiformes. – Bol. Soc. Bras. Math., 1975, v.6, N2, pp. 95–128.
In this paper, L. Dara also suggested suggested simple normal forms for the pleated singular points, however this hypothesis
is proved wrong.
38
5 Appendix.
5.1 Legendre transformation
In Lecture 2 we defined the Legendre transformation of planar curves. Recall this definition.
Let γ be such a curve given by the formula
γ : x= ϕ(τ), y= ψ(τ), (5.1)
and γ be the 1-graph of γ:
γ : x= ϕ(τ), y= ψ(τ), p=
ψ′(τ)
ϕ′(τ). (5.2)
Let L be the diﬀeomorphism (x,y,p)→(X,Y,P) given by the formula
x= P, p= X, y+ Y= xp= XP. (5.3)
Then the diﬀeomorphism L turns the curve γ in the (x,y,p)-space to the curve γ∗ in the
(X,Y,P)-space.Considertheprojectionofthecurveγ∗onthe(X,Y)-planealongtheP-axis:
γ ⊂(x,y,p) L
−−−→γ∗⊂(X,Y,P)
 
 
(5.4)
γ ⊂(x,y)−−−→ γ∗⊂(X,Y)
The curve γ∗ is called «dual» to the curve γ or «Legendre transformation» of γ.
Consider the important particular case when the curve γ is a graph of a smooth function:
y= f(x), that is, in formula (5.1) we can put ϕ(τ) = τ and ψ(τ) = f(τ). Then formula (5.2)
reads
γ : x= τ, y= f(τ), p= f′(τ).
and using the above construction, we get the dual curve
γ∗
: X= f′(τ), Y= τf′(τ)−f(τ). (5.5)
If the curve (5.5) can be written in the form Y= f∗(X) with some function f∗, it is natural
to say that the function f∗is the «Legendre transformation» of the function f. For example,
if the function f′: R →R is surjective, and f′′is not vanishing on R, then f∗is defined and
smooth on R. However if one of these conditions does not hold, the function f∗ can be not
defined or not regular at some points of R. (Consider the example: f(x) = xn with n∈N).
LetU ⊂R beanopendomain.LetC(U) betheclassofC2-smoothfunctionsf(x) : U →R
satisfying the following condition: f′′(x) >0 for all x∈U. This implies that the derivative
map f′(x) : U →U∗, where U∗:= f′(U), is surjective.
Then for any function f ∈C(U) the Legendre transformation f∗(X) : U∗→R is defined
by the following formula
f∗(X) = sup
(Xu−f(u)). (5.6)
u∈U
To prove this claim, consider the function F(u) = Xu−f(u) of the variable u∈U depending
on the parameter X ∈U∗. Since F′(u) = X−f′(u) and the map f′(x) : U →U∗is surjective,
for each value X ∈U∗ the equation F′(u) = 0 ⇔f′(u) = X has a unique solution u∗∈U.
39
From the condition f′′(x) > 0 it follows F′′(u) < 0. Hence the fucntion F(u) has a global
maximum on U at the point u∗. Therefore
f∗(X) = sup
u∈U
(Xu−f(u)) = Xu∗−f(u∗), where f′(u∗) = X, (5.7)
see the following picture. Comparing this formula with (5.5) and (5.6), we see that for any
function f(x) ∈C(U) formulas (5.4)–(5.5) and (5.6) give the same function f∗(X).
Exercise 1.
Prove that f ∈C(U) ⇒f∗∈C(U∗) and (f∗)∗
= f.
Exercise 2.
Prove the Young inequality: f(x) + f∗(X) ≥xX for ∀f ∈C(U), x∈U, X ∈U∗
.
Exercise 3.
Calculate the Legendre transformation of the function
f(x) = √1 + x2, x∈R,
using both definitions: (5.4)–(5.5) and (5.6).
Notice that for functions f / ∈C(U) the definitions of f∗by formulas (5.4)–(5.5) and (5.6)
can be non-equivalent.
Exercise 4.
Prove that the Legendre transformations of the functions f(x) and g(x) =−f(x) defined
byformulas(5.4)–(5.5)areconnectedbythefollowingrelation:g∗(X) =−f∗(−X).However
this is not true in the case of definition (5.6). For example, consider the function f(x) =
−x2/2 on U= R. Clearly, for any X the right hand side of (5.6) is equal to +∞.
Exercise 5.
DefinethesimilarLegendretransformationinthemultidimensionalcase,i.e.,forfunctions
f(x1,...,xn) : Rn →R.
Hint: In formula (5.3) put x= (x1,...,xn), p= (p1,...,pn) and xp= x1p1 +···+ xnpn,
and similarly for X and P. In formulas (5.6) and (5.7) also put Xu= X1u1 +···+ Xnun.
5.2 Lagrangian and Hamiltonian equations
Consider the space J1 with coordinates (x,y,y′) and a smooth function L(x,y,y′) of three
independent real variables.25 Suppose that for each fixed pair (x,y) the function L(x,y,y′)
as a function of the variable y′ belongs to C(R).
25Later on we put y′
= dy/dx, that’s why we use this special notation for the third variable.
40
pdy′ Ly′dy′
dy
Then the Legendre transformation of the function Lwith respect to y′(here the variables
x,y play the role of parameters) is defined and belongs to C(R). According to formulas (5.6)
and (5.7), the Legendre transformation of L with respect to y′ is defined by the relations
H(x,y,p) = py′
−L(x,y,y′), where y′
= y′(p) : p= Ly′(x,y,y′), (5.8)
here we used H instead of L∗
, p instead of X, y′ instead of u∗.
Formula (5.8) suggests doing the following change of variables in the space J1:
(x,y,y′)→(x,y,p), where p= Ly′(x,y,y′). (5.9)
By the above supposition, (5.9) defines a smooth diﬀeomorphism of J1, and the variables
(x,y,p) are global coordinates in J1
.
Consider the Euler–Lagrange equation with the Lagrangian L(x,y,y′), that is,
d
dxLy′−Ly = 0, where y′
The diﬀerential of the function H(x,y,p) from (5.8) is
=
dy
dx. (5.10)
dH= + y′dp−Lxdx−Lydy− = y′dp−Lxdx−Lydy,
since p= Ly′. Hence we get: Hx =−Lx, Hy =−Ly, Hp = y′. Finally, using equation (5.10),
the equalities p= Ly′ and y′
= dy/dx, we obtain
d
dp
Hy =−Ly =−
dxLy′ =−
dx and Hp = y′
=
dx.
Thus the Euler–Lagrange equation (5.10) in the variables (x,y,p) gives the Hamiltonian
system
dy
dp
dx= Hp,
dx=−Hy, (5.11)
where the function H(x,y,p) defined by (5.8) is the Hamiltonian corresponding to the
Lagrangian L(x,y,y′), and the correspondence being the Legendre transformation with
respect to the variable y′ («velocity»). The variable p defined by (5.9), is called «impulse»,
and (x,y,p) are called «canonical variables».
Exercise 6.
ProvetheequivalenceoftheLagrangianandHamiltoniansystemsinthemultidimensional
case: y = (y1,...,yn), y′= (y′
1,...,y′
n), p= (p1,...,pn), where pi = Ly′
. Notice that in the
i
multidimensional case the change of variables y′ → p is a local (not necessarly global)
diﬀeomorphism of the space.
Exercise 7.
Prove that if the Lagrangian Ldoes not depend on the variable x, i.e., L= L(y,y′), then
the function I(y,y′) = y′Ly′−L is a first integral of the Euler–Lagrange equation (5.10),
which is called the «energy integral», and the Hamiltonian H(y,p) is a first integral of the
Hamiltonian equation (5.11). This claim is valid in the multidimensional case, if we put
I(y,y′) = y′Ly′−L, where y′Ly′ := y′
1Ly′
1 +···+ y′
nLy′
n
Exercise 8.
Prove that if the Lagrangian Ldoes not depend on the variable yi for some i∈{1,...,n},
then the function I(x,y,y′) = Ly′
i is a first integral of the Euler–Lagrange equation (5.10),
41
.
whichiscalledthe«impulseintegral».WhatisthefirstintegralofthecorrespondingHamiltonian
equation?
Example 1.
Consider the motion of a material point in n-dimensional space with the Cartesian
coordinates y= (y1,...,yn). Let the variable xmean the time, and y′
= dy/dxthe velocity.
The kinetic energy of this mechanical system is T(y′) =m
2 (y′
i)2, where mis the mass of the
point. Assume that the potential energy of the point is a smooth function of the coordinates:
U(y), and there is no friction.
According to the «minimum action principle», the motion of the point is realized along
extremals of the action functional, i.e., it is described by the Euler–Lagrange equation (5.10)
with the Lagrangian
L(y,y′) = T(y′)−U(y) = m
2
n
(y′
i)2
−U(y).
i=1
To get the corresponding Hamiltonian system, introduce the variables pi = Ly′
i
= my′
i.
Hence in this case the change of variables y′ →p is a scaling. According to formula (5.8)
and Exercise 5, the Hamiltonian is defined by the relation
H(y,p) =
n
piy′
i−L(y,y′), where pi = my′
i ⇔ y′
i =
i=1
pi
.
m
m
p2
i
m2 + U(y) = 1
2m
Therefore
H(y,p) =
n
pi
i=1
pi
m−L y,
p
m
=
n
i=1
p2
i
m−
and the corresponding Hamiltonian system reads
dyi
dx= Hpi
=
pi
m
,
2
n
i=1
dpi
dx=−Hyi
n
p2
i + U(y), (5.12)
i=1
=−Uyi (y). (5.13)
Exercise 9.
What is the mechanical sense of the Hamiltonian?
Answer: the Hamiltonian is the total energy.
Indeed, since y′
i = pi
m, the kinetic energy is T=
m
2 (y′
i)2
1
=
2m p2
i, and from formula
(5.12) we obtain H= T + U(y). Since H(y,p) is a first integral of equation (5.13), the
function H has a constant value on each solution. The mechanical sense of this fact is energy
conservation law: the total energy of the mechanical system is constant.
Exercise 10.
Write the Hamiltonian equation for the mechanical system which consists of N material
points with masses mi, i = 1,...,N, in 3-dimensional space assuming that the potential
energy of the mechanical system is a smooth function of the coordinates of the points, and
there is no friction.
Hint: The total number of coordinates is n= 3N. Put y = (y1,y2,y3;...; yn−2,yn−1,yn),
where each triple (y3i−2,y3i−1,y3i) is the Cartesian coordinates of the i-th point. Then the
Lagrangian of this mechanical system is L(y,y′) = T(y′)−U(y), where the kinetic energy is
T(y′) = 1
2
N
mi((y′
3i−2)2 + (y′
3i−1)2 + (y′
3i)2).
i=1
42
Example 2.
and the metric
The equation of geodesic lines on a 2-dimensional smooth manifold with coordinates x,y
ds2
= ady2 + 2bdxdy+ cdx2 (5.14)
is the Euler–Lagrange equation (5.10) with the Lagrangian
L(x,y,y′) = ds
dx= a(y′)2 + 2by′+ c. (5.15)
Here the coeﬃcients a,b,c are smooth functions of the coordinates x,y.
For instance, in the case of the standard Euclidean metric ds2
= dy2 +dx2 the Lagrangian
L= (y′)2 + 1 doesnotdependonthevariablesxandy,andthecorrespondingequation(5.10)
has both energy and impulse integrals. Let’s use the impulse integral:
Ly′ =
y′
= const ⇔ y′= const.
(y′)2 + 1
This yields that the geodesics are straight lines y= αx+ β, where α,β are arbitrary real
coeﬃcients.26 Let’s write the corresponding Hamiltonian equation. The canonical variable is
p= Ly′ = y′/ (y′)2 + 1. Notice that
−1 <p=
y′
<1 and Ly′y′ =
>0 ∀y′∈R.
(y′)2 + 1
((y′)2 + 1)3
2
Thus the function L(y′) belongs to the class C(U) with U= R, and U∗ = (−1,+1). Hence
the Legendre transformation H(p) : U∗→R is defined by the relation
H(p) = py′
−L(y′), where p=
y′
⇔ y′
=
(y′)2 + 1
p
1−p2 ,
i.e., H(p) =− 1−p2, where p ∈U∗. Substituting this expression into (5.11), we get the
corresponding Hamiltonian equation.
Exercise 11.
Find the geodesic lines in the metric
1
dy2 + dx2
ds2
=
y2 (5.16)
on the upper half-plane y > 0, using the energy integral. Write the Hamiltonian equation
for the geodesics in this metric.
Remark. This metric is called the «Klein metric», it is used in the Klein–Poincar´e
model of the Lobachevsky plane (L2). In this model the «lines» on L2 are geodesics in
the metric (5.16). By Iso(L2) denote the group of the isometries of L2. This group can be
discribed as follows.
Each point (x,y) of the upper half-plane can be interpreted as the complex number
z = x+ iy. Consider the group of fractional linear transformations (FLTs):
az+ b
z →
cz+ d, where a b
c d ∈SL(2,R). (5.17)
26The attentive reader must see that here we lost the line x = 0, because we used the derivative y′
= dy/dx. Generally
speaking, we must to consider also the Lagrangian obtained by interchanging x and y.
43
Recall that the group SL(2,R) consists of matrices A∈GL(2,R) such that |A|= 1.
It is not hard to prove that FLTs (5.17) define real maps (x,y)→(x,y) which preserve
the upper half-plane and the Klein metric, that is, they define isometries of L2. More exactly,
FLTs (5.17) define a subgroup of Iso(L2). The whole group Iso(L2) consists of FLTs (5.17)
and their compositions with the transformation z →−z, i.e., (x,y)→(−x,y).
Hamiltonian equations (as well as Lagrangian equations) are not «generic» second-order
ODEs, they posesse a lot of special properties.
For instance, the divergence of Hamiltonian equations is identically zero. Indeed, let⃗
VH
be the vector field defined in the (y,p)-space by Hamiltonian equation (5.11). Then
div⃗
VH =
∂(Hp)
∂(−Hy)
∂y +
= Hpy−Hpy = 0.
∂p
Clearly, this statement is valid in the multidimensional case as well.
The vector fields⃗
V satisfying the condition div⃗
V = 0 are called «divergence free». The
phase flow of any divergence free vector field⃗
V preserves the volume in the phase space. In
particular, the phase flow of the Hamiltonian vector field⃗
VH preserves the volume in the
(y,p)-space. Using the correspondence between Lagrangian and Hamiltonian equations, one
can establish the same property for Euler–Lagrange equations.
In the Examples 1 and 2 we dealt with smooth Lagrangians satisfying the condition
Ly′y′ ̸= 0. In the multidimensional case the analogous condition is
|Ly′y′|:=
∂2L
∂y′
i∂y′
j
̸= 0, (5.18)
that is, the Hessian matrix of the function L with respect to y′ = (y′
1,...,y′
n) is non-zero.
If condition (5.18) holds true, the Legendre transformation of L by y′ is defined (at least,
locally), and the passage to the canonical variables y′→p= Ly′ is a local diﬀeomorphism.
In most «reasonable problems» Lagrangians are smooth and satisfy condition (5.18). For
instance, in classical mechanics most of Lagrangians have the form L= T−U, where the
kinetic energy T is a non-degenerated quadratic form of y′= (y′
1,...,y′
n) and the potential
energy U does not depend on y′. However there are some exceptions.
The Lagrangian L(x,y,y′) is called «singular» at the point (x,y,y′), if at this point
condition (5.18) does not hold: |Ly′y′|= 0 or |Ly′y′|is the indeterminacy 0/0. The simplest
example of singular Lagrangians can be obtained if we consider geodesic lines in non-regular
metrics (here the Lagrangian is the square root of the metric).
For example, let S be a surface in a Euclidean space. Then the geodesic lines on S are
extremals of the length functional, i.e., solutions of the Euler–Lagrange equation, where L
is the square root of the metric ds2 induced on S by the metric of the ambient Euclidean
space. The Lagrangian L= √ds2 is singular at the points where the surface S in not regular
(cone, cuspidal edge, swallow tail, etc.). Another example: let S be a regular surface in a
pseudo-Euclidean space E. Then the metric ds2 induced on S by the metric of the ambient
space E, is indefinite, and ds2 is degenerated at the points where Sin tangent to the isotropic
cone of E. At such points the Lagrangian L= √ds2 is singular.27
27See, for example:
A.O. Remizov. Geodesics on 2-surfaces with pseudo-Riemannian metric: singularities of changes of signature. Mat. Sb.,
200:3 (2009), pp. 75–94.
A.O. Remizov. Singularities of a geodesic flow on surfaces with a cuspidal edge. Proceed. Steklov Institute of Math. 268
(2010), pp. 258–267.
44
Singular Lagrangians also occur in theoretical physics in describing relativistic eﬀects. For
the first time they were studied in 1950 by Dirac, Anderson, and Bergman, and later on,
by many other authors.28 In particular, an important problem is the Hamiltonian formalism
for the Euler–Lagrange equation in a neighborhood of the singular point, since the standard
passagetothecanonicalcoordinatesy′→p= Ly′atsuchpointsisnotalocaldiﬀeomorphism.
The reader may ask a natural question: why do we need to pass from the Euler–Lagrange
equation to the Hamiltonian one? In the examples 1 and 2 considered above, the Hamiltonian
equation does not give us any advantages, and the passage to the canonical coordinates
looks like a waste of time. However in many cases the Hamiltonian approch gives a lot of
advantages.29
5.3 Hamiltonian equations and integrating factor
Consider the Hamiltonian vector field
dx
dt= Hy(x,y),
dy
dt=−Hx(x,y), (5.19)
where x,y ∈R are the independent (phase) variables, t plays the role of time, and the
Hamiltonian H(x,y) is a smooth function. (Formula (5.19) concides with the previous
formula (5.11) up to a renaming the variables. The only diﬀerence is that now we deal
with the case when the Hamiltonian H does not depend on the time.)
The vector field (5.19) is divergence free. The inverse statement is also true:
Exercise 12.
Prove that any smooth divergence free vector field⃗
V:
dx
dt= v(x,y),
dy
dt=−w(x,y) (5.20)
in a simply connected open domain D of the (x,y)-plane is a Hamiltonian one (recall that
an open domain D is called «simply connected» if any continuous loop in D is homotopic
to a point).
Solution: To prove the statement it is necessary and suﬃcient to show that there exists a
smooth function H(x,y) such that v = Hy and w= Hx. It is well-known30 that in a simply
connected open domain such a function H exists ⇔vx = wy ⇔div⃗
V= vx−wy = 0.
Give the following definition: the vector fields⃗
V and⃗
V1 are «collinear» if⃗
⃗
V1 = ϕ
V, where
ϕ is a smooth non-vanishing scalar function of the same variables as the fields. This means
that⃗
V and⃗
V1 have the same integral curves, but the velocities of motion on these curves
are diﬀerent. Using the notion of a direction field (Lecture 2), we can say that vector fields
⃗
V and⃗
V1 are collinear iﬀ they define the same direction field.
Exercise 13.
Prove that in a neighborhood of any non-singular point any smooth vector field is locally
collinear to a divergence free vector field (hence, to a Hamiltonian one).
28See, for example:
[1] P.A.M. Dirac. Lectures on Quantum Mechanics. – Yeshiva University, New York (1964).
[2] J.F. Cari˜nena. Theory of singular Lagrangians. – Fortschr. Phys., 38 (1990), No. 9, pp. 641–679.
29See the book [1] cited above. Hamiltonian format is also native for Pontryagin’s maximum principle.
30V.A. Zorich «Mathematical Analysis», vol. II, chapter «Elements of Vector Analysis and Field Theory». In this book the
reader can also find the explaination why the condition that D is simply connected is important.
45
Solution: Let⃗
V be a smooth vector field written in the form (5.20) in a neighborhood of 0
such that⃗
V(0) ̸= 0. We have to establish the local existence of a smooth function ϕ(x,y) ̸= 0
⃗
⃗
such that the vector field ϕ
V is divergence free: div (ϕ
V) = 0. This gives the first-order PDE
vϕx−wϕy + ϕ(vx−wy) = 0 (5.21)
with known functions v(x,y), w(x,y) and the unknown function ϕ(x,y).
The condition |v(0)|+ |w(0)|̸= 0 provides the local existence (and uniqueness) of the
solution of PDE (5.21) with any initial condition ϕ Γ
= ϕΓ, where Γ is a regular curve on
the (x,y)-plane passing through the origin transversal to⃗
V (one can put Γ = one of the
coordinate axis: x = 0 or y = 0), and ϕΓ is a smooth function on Γ. Choosing the initial
function ϕΓ such that ϕΓ(0) ̸= 0, we get the required function ϕ.
In other words, this means that any smooth vector field (5.20) can be transformed into a
Hamiltonian one in a neighborhood of a non-singular point, using appropriate regular change
of the time t.
The function ϕ found above is called an «integrating factor» or «Jacobi multiplier» of
the vector field (5.20) and the corresponding diﬀerential equation wdx+ vdy= 0. The facts
proved in Exercises 12, 13 can be used for the exact solution of this equation. Indeed, after
multiplication the both sides of the equation wdx+ vdy = 0 by the function ϕ(x,y) ̸= 0
satisfying equation (5.21), we get the equivalent equation
ϕwdx+ ϕvdy= 0 ⇔ ∃H : Hxdx+ Hy dy= 0 ⇔ dH(x,y) = 0,
which has the general solution H(x,y) = const.
At first sight, this trick does not give any advantages: we just reduce the solution of
equation wdx+ vdy = 0 to the solution of another diﬀerential equation (5.21). However it
is suﬃcient to find only one partial solution of (5.21). There exist a lot of concrete types
of ODEs with known recipes for integrating factors. «The masters of integrating diﬀerential
equations (Jacobi, for example) attained great success in the solution of specific applied
problems using this technique.» (V.I. Arnold). For example:
Exercise 14.
Prove that the integrating factor of the equation wdx+ vdy= 0 satisfies the PDE
∂ln ϕ
∂ln ϕ
v
∂x−w
= wy−vx,
∂y
and if the function (wy−vx)/v= a does not depend on y, the integrating factor is ϕ=
exp a(x) dx ; if the function (wy−vx)/w= bdoes not depend on x, the integrating factor
is ϕ= exp− b(y) dy.
Remark that we used the condition⃗
V ̸= 0 for prooving the existence of an integrating
factor. Does an integrating factor exist in neighborhoods of singular points of vector fields?
Further we will always assume that 0 be a non-degenerated singular point of vector field⃗
V
given by (5.20). The term «non-degenerated» means that both eigenvalues λ1,2 of the linear
part of⃗
V at 0 are non-zero, that is, the Jacobi matrix
A=
⃗
∂
V
∂(x,y)(0) = ∂(v,−w)
∂(x,y) (0)
46
is non-degenerated (= invertible). Then there are 4 possible phase portraits of⃗
V in a
neighborhood of 0:
Stressthatifv(x,y) andw(x,y) arelinearfunctions,thenthecaseofcenter⇔λ1,2 = ±iω,
where iis the imaginary unit and ω>0. However if v(x,y) and w(x,y) are non-linear, there
is only implication: center ⇒λ1,2 = ±iω, ω > 0. In this case the diﬀerence between center
(the integral are loops) and focus (the integral are spirals) is determined by the non-linear
terms.
Exercise 15.
Prove that in the case of node (Jordan node and dicritical node as well) and in the case
of focus the vector field⃗
V does not have an integrating factor in a neighborhood of 0.
Solution: If a function I(x,y) is a first integral of the vector field⃗
V, then I is a first
⃗
⃗
integral of any collinear vector field ϕ
V. Suppose that the field ϕ
V is divergence free, then
⃗
it is Hamiltonian vector field with some Hamiltonian function H(x,y); hence both fields ϕ
V
and⃗
V possess the continuous first integral I= H.
Suppose that in the case of node or focus there exists a continuous function I(x,y) such
thatI(γ(t)) ≡const (theconstantdependsonγ(·))foreachintegralcurveγ.Sinceallintegral
curves tend to 0 as t → ±∞(the sign «±»=«+»/«−» corresponds to stable/unstable
equilibrium point 0), we have I(γ(t))→I(0) as t →±∞⇒I(γ(t)) ≡I(0) for all integral
curves γ(·). Since for each point (x,y) there exists the integral curve γ passing through this
point, we get I(x,y) ≡I(0), i.e., I is a constant function. Thus we proved that⃗
V does not
have a continuous first integral in a neighborhood of 0 ⇒⃗
V does not have an integrating
factor in a neighborhood of 0.
Remark. However discountinuous first integrals exist. For example, the dicritical node
dy/dx= y, dp/dx= p has the first integral I= y/p discountinuous at the origin.
Thus we proved that node and focus do not have integrating factor. What about saddle
and center? First of all, we can try to apply the reasoning from Exercise 15 to saddle and
center. But unlike node and focus, it does not give the indentity I(x,y) ≡I(0). In the case of
saddle we only conclude that I(γ(t)) ≡I(0) for two separatrices, but not for others integral
curves.
Exercise 16.
In the case of saddle prove the following necessary condition: if the field⃗
V has an
integrating factor in a neighborhood of 0 then λ1 +λ2 = 0 (recall that λ1,2 are the eigenvalues
of the linear part of⃗
V at 0, i.e., of the matrix A defined above).
Solution: From the identity
⃗
div (ϕ
V) = ϕdiv⃗
V + ⟨⃗
V,∇ϕ⟩
47
itfollowsthatatthesingularpoint(⃗
⃗
V(0) = 0)wehavetheequalitydiv (ϕ
V)(0) = ϕdiv⃗
V(0).
⃗
Hence div (ϕ
V)(0) = 0 ⇔div⃗
V(0) = 0. Thus if the field⃗
V is collinear to a divergence free
⃗
field ϕ
V, then div⃗
V(0) = 0. Taking into account the relation div⃗
V(0) = tr A(0), we get the
equality λ1 + λ2 = 0.
Remark. The attentive reader may say the last proof can be also used for proving the
previous Exercise 15. Indeed, among the above types of non-generated singular points (node,
saddle, focus, center) only saddle and center satisfy the necessary condition λ1 + λ2 = 0.
This proofs the statement from Exercise 15.
However I prefer to give both proofs simultaneously, because they are based on absolutely
diﬀerent ideas. The first one uses the topological (more «rough») properties of the phase
portrait, but the second proof uses the eigenvalues of the linear part, which are smooth, but
not topological invariants of vector fields.31 Moreover, the first proof can be also used for
some types of degenerated singular points such that λ1,2 = 0.
Thus we proved that a vector field may have an integrating factor in a neighborhood
of a non-degenerated singular point 0 only if 0 is a center or saddle with the eigenvalues
λ1,2 = ±α. This condition is necessary, but is it suﬃcient? In fact, no:
Exercise 17.
Prove that the vector field⃗
V has an integrating factor in a neighborhood of a non-
degenerated singular point 0 if and only if there exist smooth local coordinates such that⃗
V
is collinear to the linear field
dx
dy
dt= εy,
dt= x, where ε= ±1. (5.22)
Solution: Consider the vector field⃗
V given by formula (5.20).
⇒ Suppose that ϕis the integrating factor of⃗
⃗
V, that is, the field ϕ
V is Hamiltonian
⇒ϕv= Hy and ϕw= Hx for a smooth function H(x,y). By the Morse Lemma, we can
⃗
choose smooth local coordinates such that H = (−x2 + εy2)/2 ⇒the field ϕ
V has the
form (5.22). Thus in these («canonical») coordinates the vector field⃗
V is collinear to (5.22).
⇐ Notice that any diﬀeomorphism (smooth change of variables) turns any non-
degenerated singular point of⃗
V into a non-degenerated singular point (moreover, it preserves
the eigenvalues of the linear part of⃗
V). Suppose that⃗
V is collinear to (5.22) in some
coordinates (x,y), i.e.,⃗
V is given by the formula
dx
dy
dt= ϕεy,
dt= ϕx, where ε= ±1, (5.23)
with a smooth non-vanishing function ϕ.
The vector field (5.23) has the first integral (−x2 + εy2)/2 ⇒in any another coordinates
the field⃗
V has the first integral I(x,y) obtained from the previous one by the corresponding
change of variables. Clearly, the function I(x,y) also has a non-degenerated critical point at
0. Thus we proved that in the initial coordinates the vector field (5.20) has the first integral
I(x,y) ⇒vIx−wIy = 0 ⇒v= ψIy and w= ψIx for some function ψ(x,y), that is,
dx
dy
dt= ψIy,
dt=−ψIx.
31Homeomorphisms do not preserve the eigenvalues. In particular, node (including Jordan and dicritical ones) and focus are
topologically equivalent, see e.g.:
• V.I. Arnold, Yu.S. Il’yashenko. Ordinary diﬀerential equations. – Dynamical systems I, Encyclopaedia Math. Sci., vol. 1.
• Ph. Hartman. Ordinary Diﬀerential Equations.
48
dy
dt=−(x2 + y2) (5.24)
From the condition that 0 is a non-degenerated singular point, it follows that ψ(0) ̸= 0. Thus
the vector field (5.20) is collinear to the Hamiltonian vector field with H= I.
Example 3. Consider the vector field⃗
V given by formula (5.20) with the functions
v(x,y) = xand w(x,y) = y. The equation dy/dx=−x/yhas the first integral I= xy, which
can be brought to the required form (−x2 + y2)/2 using a linear change of the variables.
The condition that 0 is a non-degenerated singular point provides the condition ϕ ̸= 0
for the integrating factor. Indeed, consider the following example.
Example 4. The vector field
dx
dt= x2 + y2
,
is obtained from the Hamiltonian vector field
dx
dt = 1,
dy
dt=−1
(the Hamiltonian function H= x+ y) after multiplication by the function x2 + y2, which
vanishes at 0. It is not hard to see that field (5.24) does not have an integrating factor, i.e.,
it cannot be brought to a Hamiltonian vector field by means of multiplication by a smooth
non-vanishing function ϕ(x,y). Indeed, such smooth function ϕ satisfies the equation
∂
∂x (x2 + y2)ϕ−
∂
∂y (x2 + y2)ϕ = (x2 + y2)(ϕx−ϕy) + 2(x−y)ϕ= 0,
which implies that ϕ(0) = 0.
Remark. The statements of both Exercises 15 and 16 can be derived from Exercise 17.
However it seems reasonable to give them separately, because the proofs in Exercises 15, 16
can be used in more general situation than the last one. In fact, the proof of Exercise 17 is
based on the Morse lemma, which is applicable only for non-degenerated singular points of ⃗
V. On the other hand, it is not hard to see that the statements in Exercises 15, 16 can be
applied to degenerated singular points.
Finally, consider the multidimensional Hamiltonian vector field
dxi
dt= Hyi (x,y),
dyi
dt=−Hxi (x,y), i= 1,...,n, (5.25)
where x = (x1,...,xn) and y = (y1,...,yn) are the independent (phase) variables, t plays
the role of time, and the Hamiltonian H(x,y) is a smooth function. The vector field (5.25)
is divergence free.32
However the inverse implication: «divergence free ⇒Hamiltonian field» in the case n>1
is false (give an example!).
Exercise 18. Let⃗
V be the Hamiltonian vector field given by formula (5.25) and S be
a smooth invariant manifold of⃗
V. Is the restriction⃗
V S a Hamiltonian vector field? Is the
restriction⃗
V S a divergence free vector field?
32From the correspondence between Lagrangian and Hamiltonian equations it follows that vector fields generated by Euler–
Lagrange equations, are also divergence free. Remark that this statement for Hamiltonian equations of any dimension is trivial,
but for the multidimensional Euler–Lagrange equations it requires some calculations.
49
Exercise 19.
Prove the famous Poincar´e Recurrence Theorem:
Let gt be the phase flow of a Hamiltonian vector field⃗
V which maps a bounded region D
of the phase space onto itself: gt(D) = D (for example, the field⃗
V is defined on a smooth
compact 2n-dimensional manifold D). Then in any neighborhood U of any point (x,y) ∈D
there is a point (x′,y′) ∈U which returns to U, that is, ∃n∈N: gn(x′,y′) ∈U.
Hint:⃗
V is Hamiltonian ⇒⃗
V is divergence free ⇒⃗
V preserves the volume of the phase
space ⇒the series
∞
n=0
diverges ⇒∃k,l∈N: gk(U) ∩gk(U) ̸= ∅.
Vol (gn(U)) =
∞
n=0
Vol (U)
The reader interested in further studying of Hamiltonian systems, is referred to the book:
•V.I. Arnold. Mathematical Methods of Classical Mechanics.
50
HOT Theory and the Evolution of Consciousness
One recalls that LeDoux (2019) makes a different prediction
about when consciousness arose in history with a theory-heavy HOTClouser 176
approach. LeDoux claims that, if HOT theory is true and verbal
report is the only evidence we have of consciousness, then the only
evidence of consciousness that we can have regards humans. He
believes that humans had consciousness with the birth of modern
homo sapiens and they are the only creatures that have it because
humans are the only ones with the necessary brain regions for HOTs,
likely to be found in the dorsolateral prefrontal cortex (dlPFC). Since
humans are the only creatures available to give a verbal report due to
language and are the only ones with a developed prefrontal cortex,
then humans are the only creatures with HOTs and consciousness.
Again, this answer is startling to many theorists.
I argue now that there is at least one way to reconcile what
may seem to be this deep debate among consciousness researchers.
Rosenthal makes an important distinction between types of
consciousness that LeDoux did not consider in his predictions.
Verbal report is often considered evidence for what we might call
“cognitive consciousness,” but not necessarily for what we might call
“qualitative consciousness.” The difference between these types of
consciousness involves what kind of FO mental states a creature may
have HOTs about. Qualitative psychological states include
perceptions and sensations, while cognitive, or non-qualitative, states
include thoughts, desires, and intentions.
According to Rosenthal, common sense holds that many
nonhuman animals such as dogs have qualitative but not cognitive
consciousness. There is reason to think that dogs can feel pain
consciously, but there is little reason to think that dogs may have
conscious thoughts and desires about the world. Since dogs cannot
give a verbal report, there are no experimental findings on dogs
having cognitive consciousness. However, there are experimental
findings concerning conscious perception in other mammals. For
example, it is possible to induce blindsight in monkeys (Yoshida &
Isa, 2015), showing that at least some animals can be induced into
unconsciously perceiving that which may be ordinarily conscious.
This crucial difference in qualitative and cognitive
consciousness is often overlooked by theories of consciousness in
humans and other creatures. But given this distinction, it is easy to
see why some debates are not really debates at all. HOT theorists can
happily grant that many nonhuman animals have qualitative
consciousness, while still maintaining that cognitive consciousnessClouser 177
may have evolved rather late in history, and perhaps only in humans.
Therefore, I will only focus on cognitive consciousness and the
question of when it arose in evolutionary history.
Given that the most promising theory, HOT theory, and
current evidence suggest that cognitive consciousness only occurs in
humans, it might seem that it arose at the same time that homo sapiens
evolved. However, I argue that we still must further distinguish
between having the capacity for cognitive consciousness and actually
having it. Knowing the difference between having a capacity for
consciousness and having it will yield very different results about
when consciousness arose in history.
LeDoux seems to assume that having the relevant neural
structures for HOTs indicates that humans automatically have
consciousness. This is a common assumption in cognitive
archaeology as well, in that evidence of the relevant neural structures
is necessary and that sufficient evidence of certain mental functions
occurred (Binford, 1973). But there is no reason to assume that
because humans may have always had a capacity for a mental
function, such as consciousness, that they actually exercised or
developed that function.
This is especially true if HOT theory is correct. After all,
HOTs are a type of ordinary thought and just because people can
have that type of thought, it does not mean that they necessarily do.
For example, all humans have the capacity to think about hard
mathematical topics, such as calculus. But just because anyone can
have thoughts about calculus does not mean that we do have them
or that having such thoughts is necessary to us as humans. So, it is
not obvious that having language capacity or the right
neurophysiological structures shows that humans had cognitive
consciousness.
The latest possible concrete evidence that we could find for
such consciousness would come in the form of a verbal report of
mentality through language. Today, the Sumerian language of
southern Mesopotamia is widely regarded as the first known written
language, emerging around 5,000 years ago (Kenanidis, 2013).
Extensive research into the language could possibly reveal verbal
expressions of consciousness earlier in history. Verbal expressions of
consciousness would need to be examples of not simply expressing
thoughts or perceptions, but expressing awareness that one thinks orClouser 178
perceives their own thoughts. An example could be a statement such
as “I am hungry.” This would show that one is aware of their own
desires and thoughts they have. An expression of simple hunger
could look like “Get food now.” There may have been a period
before consciousness arose when people simply had FO states of
hunger that they could verbally express without being aware that they
were hungry and thus were having HOTs about such states.
Although it is not guaranteed that Sumerians were conscious
when writing their language around 5,000 years ago, this timeframe
still feels incredibly late in history for the arrival of cognitive
consciousness. For simplicity, this project will not regard the hunt
for the first verbal expressions of consciousness through past
literature. To move forward, we must explore whether or not there
could be nonverbal expressions of consciousness that occur before
written language that would provide evidence of the relevant kind of
HO awareness.
V. Exploring the Archaeological Record
If HOT theory is true, what nonverbal, behavioral, and thus
material expressions of cognitive consciousness would we expect to
see in the archaeological record? These are the implications when
people express their HO awareness of their mental lives. I now offer
a hypothesis regarding the material correlates of HOTs. If sound,
this theoretical model could then be used and applied to already
known archaeological cases to determine when consciousness
evolved.
In the HOT theory that Rosenthal (2008) develops,
consciousness has no utility or function, so there would be no
individual material or behavioral correlates to having it. Any
immediate action that is driven by mental states that are conscious
could arguably be driven by those same states unconsciously. The
only evidence we could have for consciousness, then, would be
verbal reports in the form of written language.
However, I claim that HOT theory is still compatible with a
version of consciousness with some group utility. Consciousness
may not have any direct function for the individual, but the
possession of it may lead to social consequences that have
implications in the material record. The consequences of
consciousness may be apparent in groups and societies on a socialClouser 179
level. We can understand this claim through the evaluation of cultural
evolution theories of prosocial behaviors (e.g., Norenzayan &
Gervais, 2011).
One such prosocial behavior that has a large role in culture is
the introduction of religion and religious behaviors (Norenzayan &
Gervais, 2011). Religion is a cultural byproduct of promoted
prosocial behaviors and facilitates the benefit of others in group
settings (Norenzayan et. al., 2016). Religion has four features that
have remained stable across all time periods and cultures, and it is
commonly believed among cognitive archaeologists that one
necessary feature of religion is the individual’s ability to perceive
other minds and infer the thoughts of others (Norenzayan &
Gervais, 2011). This ability is what facilitates the attribution of
desires and beliefs to gods because they are humanlike and
recognizable. Additionally, religious beliefs are a byproduct of the
concern of individuals’ reputations socially. An individual within a
group becomes aware of their own place and status within their
group and the place of others, resulting in religious behaviors that
promote the welfare and cooperation of shared ideas in a group to
make stronger bonds within it. Religious beliefs have inherent
cooperative intentions, facilitating the rise and stability of larger
communities (Norenzayan & Gervais, 2011).
This core feature of religion, that an individual is aware of
their own thoughts and others’ thoughts within a group, is a
byproduct of HO awareness. Religion could not be facilitated
without this understanding of one another’s beliefs and desires—and
thus arguably of one’s own mental states as well. As such, we can
assume that the behavioral and material consequences of the
introduction of HO awareness and cognitive consciousness would
facilitate religious behaviors that are intended to promote the welfare
of a social group. Religion as a consequence of HO awareness would
infer that consciousness was necessary for religion to occur, dating
back to before religious activity had begun.
In the archaeological record, early human behavior and
cognitive abilities are still not well understood. As the topic has
become more popular in recent years, more research is being
released. We can find accounts of prosocial behaviors that were
intended to promote cooperation dating back even before homo
sapiens to the Neanderthals. We can expect to find accounts ofClouser 180
increased prosocial behaviors regarding contribution to group
welfare, before religion, as indicators of the beginnings of
consciousness. HO awareness benefited groups by promoting
stability and cooperation from shared beliefs. Twomey (2013) claims
that prosocial behaviors associated with religion, like future directed
cooperation and resolving social dilemmas, can be seen as early as
200,000 years ago. These cognitive abilities can be implied through
behaviors related to controlled fire creation (Twomey, 2013). To
control fire, not just use fire, humans needed a complex variety of
cognitive skills. Controlling fire requires intensive planning, group-
level cooperation, intentionality, and social awareness (Twomey,
2013). Although evidence of religious behaviors is currently scarce
when studying ancient humans, we can view similar prosocial
behaviors in other actions, like controlling fire. These types of
actions are sufficient behavioral and material correlates for the
evidence of introduced cognitive consciousness within species.
Even with this claim, is there a way to imagine religious and
prosocial behaviors without necessarily having HOTs? Some may
claim that it is imaginable. We can think of a group of people who
are not conscious, but still can have religious thoughts and perform
religious behaviors. Why would HOTs be necessary if we could
imagine this type of scenario?
But why would there be religious behaviors at all if there was
no purpose for them? Religion is a part of culture, which provides
important social benefits. These behaviors must have occurred as a
response to something, which I claim was the introduction of
consciousness to the human species. Without consciousness and
HOTs, there would be no purpose to even partake in religious
behaviors, as humanity would still only be focused on survival.
Consciousness adds a certain quality to life and enhances it in social
ways.
VI. Conclusions
We now have a much clearer understanding of the issue at
hand concerning when consciousness may have arisen in
evolutionary history. We can say with confidence that humans were
conscious when they could verbally report their higher-order mental
states. This may have occurred late in evolutionary history, around
5,000 years ago. If we had accepted previous predictions likeClouser 181
LeDoux’s, consciousness would have arisen with the beginnings of
homo sapiens, around 300,000 years ago because of neurophysiological
changes specific to the species.
In general, there is continually much debate around the
origins of consciousness. This paper helps to identify these problems
concerning consciousness and further claims that we can view the
behavioral implications of consciousness through prosocial
behaviors around 200,000 years ago. We have only begun to explore
the implications of Higher-Order-Thought theory of consciousness
through the archaeological record. This paper will start the long
journey of this task at hand.
Clouser 182
References
Baars, B. (2005). “Global Workspace Theory of Consciousness:
Toward a Cognitive Neuroscience of Human Experience.”
Progress in Brain Research 150: 45-53.
Birch, Jonathan (2022). “The Search for Invertebrate
Consciousness.” Nous 56: 133-153.
Birch, Jonathan (2021). “The Hatching of Consciousness.” Springer
43: 121.
Descartes, R. (1641). “Meditations on First Philosophy.” In J.
Cottingham et al., (Eds.), The Philosophical Writings of Descartes,
Vol. II. Cambridge: Cambridge University Press.
Galway-Witham, J. & Stringer, C. (2018). “How did Homo Sapiens
Evolve?” Science 360: 1296-1298.
Greenwood, Veronique (2021). “Sleep Evolved Before Brains.
Hydras Are Living Proof.” Quantamagazine.
Godfrey-Smith, Peter (2020). Metazoa: Animal Minds and the Birth of
Consciousness. London: William Collins.
Halina, M., Harrison, D., and Klein, C. (2022). “Evolutionary
Transition Markers and the Origins of Consciousness.”
Journal of Consciousness Studies 29, no. 3-4: 62-77.
Kletenik, I., et al. (2022). “Network Localization of Unconscious
Visual Perception in Blindsight.” Annals of Neurology 91: 217-
224.
Laland K, Seed A (2021). “Understanding Human Cognitive
Uniqueness.” Annual Review of Psychology 4: 689-716.
LeDoux, Joseph (2019). The Deep History of Ourselves: The Four-Billion-
Year Story of How We Got Conscious Brains. New York: Viking
Press.
Metzinger, Thomas. (Ed.). (2000). Neural Correlates of Consciousness:
Empirical and Conceptual Questions. Boston: MIT Press.
Nagel, Thomas. (1974). “What is it Like to Be a Bat?” Philosophical
Review 83, no. 4: 435-50.
Norenzayan, A. and Gervais, W. (2011). The Cultural Evolution of
Religion.” in Creating Consilience: Integrating Science and the
Humanities. Oxford: Oxford University Press.
Norenzayan, Ara, et al. (2016). “The Cultural Evolution of Prosocial
Religions.” Behavioral and Brain Sciences 39. Cambridge:
Cambridge University Press.
Clouser 183
Pain, Ross (2022). “Stone Tools, Predictive Processing and the
Evolution of Language.” Mind & Language 38, no. 3: 1-21.
Rosenthal, David (2008). “Consciousness and Its Function.”
Neuropsychologia 46: 829–840.
Seth, Anil & Bayne, Tim (2022). “Theories of
Consciousness.” Nature Reviews Neuroscience 23: 439-452.
Twomey, T. (2013). “The Cognitive Implications of Controlled Fire
Use by Early Humans.” Cambridge Archaeological Journal 23 (1),
113-28.
Tye, Michael (2016). Tense Bees and Shell-Shocked Crabs: Are Animals
Conscious? New York:
Oxford University Press.
Weisberg, Josh (2011). “Misrepresenting Consciousness.”
Philosophical Studies 154 no. 3: 409-433.
Yoshida, Masatoshi & Isa, Tadashi (2015). “Signal Detection
Analysis of Blindsight in Monkeys.” Scientific Reports 5.
Clouser 